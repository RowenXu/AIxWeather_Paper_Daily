<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 24 Dec 2025 03:25:06 +0000</lastBuildDate>
    <item>
      <title>AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</title>
      <link>http://arxiv.org/abs/2512.20407v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rajdeep Chatterjee, Sudip Chakrabarty, Trishaani Acharjee, Deepanjali Mishra&lt;/p&gt;&lt;p&gt;Unmanned aerial vehicles (UAVs), commonly known as drones, are increasingly used across diverse domains, including logistics, agriculture, surveillance, and defense. While these systems provide numerous benefits, their misuse raises safety and security concerns, making effective detection mechanisms essential. Acoustic sensing offers a low-cost and non-intrusive alternative to vision or radar-based detection, as drone propellers generate distinctive sound patterns&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20407v1</guid>
      <pubDate>Tue, 23 Dec 2025 14:55:08 +0000</pubDate>
    </item>
    <item>
      <title>Simplifying Multi-Task Architectures Through Task-Specific Normalization</title>
      <link>http://arxiv.org/abs/2512.20420v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mihai Suteu, Ovidiu Serban&lt;/p&gt;&lt;p&gt;Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges. Architectural solutions often introduce elaborate task-specific modules or routing schemes, increasing complexity and overhead. In this work, we show that normalization layers alone are sufficient to address many of these challenges&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20420v1</guid>
      <pubDate>Tue, 23 Dec 2025 15:02:12 +0000</pubDate>
    </item>
    <item>
      <title>Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit</title>
      <link>http://arxiv.org/abs/2512.20423v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Adam Elaoumari&lt;/p&gt;&lt;p&gt;The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers. While providing a reproducible toolkit to generate, intercept and analyze DoH exfiltration, and comparing Machine Learning vs threshold-based detection under adversarial scenarios. The originality of this project is the introduction of an end-to-end, containerized pipeline that generates configurable file exfiltration over DoH using several parameters (e.g., chunking, encoding, padding, resolver rotation)&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20423v1</guid>
      <pubDate>Tue, 23 Dec 2025 15:07:17 +0000</pubDate>
    </item>
    <item>
      <title>High Dimensional Data Decomposition for Anomaly Detection of Textured Images</title>
      <link>http://arxiv.org/abs/2512.20432v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ji Song, Xing Wang, Jianguo Wu, Xiaowei Yue&lt;/p&gt;&lt;p&gt;In the realm of diverse high-dimensional data, images play a significant role across various processes of manufacturing systems where efficient image anomaly detection has emerged as a core technology of utmost importance. However, when applied to textured defect images, conventional anomaly detection methods have limitations including non-negligible misidentification, low robustness, and excessive reliance on large-scale and structured datasets. This paper proposes a texture basis integrated smooth decomposition (TBSD) approach, which is targeted at efficient anomaly detection in textured ima&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20432v1</guid>
      <pubDate>Tue, 23 Dec 2025 15:21:18 +0000</pubDate>
    </item>
    <item>
      <title>Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI</title>
      <link>http://arxiv.org/abs/2512.20436v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Muhammad Usman, Azka Rehman, Muhammad Mutti Ur Rehman, Abd Ur Rehman, Muhammad Umar Farooq&lt;/p&gt;&lt;p&gt;Accurate segmentation of ischemic stroke lesions from diffusion magnetic resonance imaging (MRI) is essential for clinical decision-making and outcome assessment. Diffusion-Weighted Imaging (DWI) and Apparent Diffusion Coefficient (ADC) scans provide complementary information on acute and sub-acute ischemic changes; however, automated lesion delineation remains challenging due to variability in lesion appearance.   In this work, we study ischemic stroke lesion segmentation using multimodal diffusion MRI from the ISLES 2022 dataset&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20436v1</guid>
      <pubDate>Tue, 23 Dec 2025 15:24:31 +0000</pubDate>
    </item>
    <item>
      <title>Quantum Bayesian Optimization for the Automatic Tuning of Lorenz-96 as a Surrogate Climate Model</title>
      <link>http://arxiv.org/abs/2512.20437v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Paul J. Christiansen, Daniel Ohl de Mello, Cedric Brügmann, Steffen Hien, Felix Herbort, Martin Kiffner, Lorenzo Pastori, Veronika Eyring&lt;/p&gt;&lt;p&gt;In this work, we propose a hybrid quantum-inspired heuristic for automatically tuning the Lorenz-96 model -- a simple proxy to describe atmospheric dynamics, yet exhibiting chaotic behavior. Building on the history matching framework by Lguensat et al. (2023), we fully automate the tuning process with a new convergence criterion and propose replacing classical Gaussian process emulators with quantum counterparts&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20437v1</guid>
      <pubDate>Tue, 23 Dec 2025 15:26:24 +0000</pubDate>
    </item>
    <item>
      <title>Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</title>
      <link>http://arxiv.org/abs/2512.20469v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding&lt;/p&gt;&lt;p&gt;AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.   However, scaling agentic science rem&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20469v1</guid>
      <pubDate>Tue, 23 Dec 2025 16:04:41 +0000</pubDate>
    </item>
    <item>
      <title>Even Small Companies Can Save Lives by Reducing Emissions</title>
      <link>http://arxiv.org/abs/2512.20473v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Daniel Baldassare, Abby Lute, Hikari Murayama, Cora Kingdon, Christopher Schwalm&lt;/p&gt;&lt;p&gt;Global warming is often framed in broad planetary numbers such as the 1.5 C and 2 C warming thresholds, creating the false impression that individual corporations efforts to reduce emissions are meaningless in the absence of collective action. This perspective causes companies to reduce ambition towards voluntarily cutting emissions, as they believe their pollution has negligible impacts on its own. Reframing the issue to focus on the life-saving potential of individual corporate actions empowers companies to act and holds them accountable for inaction&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20473v1</guid>
      <pubDate>Tue, 23 Dec 2025 16:08:08 +0000</pubDate>
    </item>
    <item>
      <title>Benchmarking LLMs for Predictive Applications in the Intensive Care Units</title>
      <link>http://arxiv.org/abs/2512.20520v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chehak Malhotra, Mehak Gopal, Akshaya Devadiga, Pradeep Singh, Ridam Pal, Ritwik Kashyap, Tavpritesh Sethi&lt;/p&gt;&lt;p&gt;With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20520v1</guid>
      <pubDate>Tue, 23 Dec 2025 17:08:31 +0000</pubDate>
    </item>
    <item>
      <title>ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification</title>
      <link>http://arxiv.org/abs/2512.20523v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Masahiro Kato&lt;/p&gt;&lt;p&gt;This study proposes Riesz representer estimation methods based on score matching. The Riesz representer is a key component in debiased machine learning for constructing $\sqrt{n}$-consistent and efficient estimators in causal inference and structural parameter estimation. To estimate the Riesz representer, direct approaches have garnered attention, such as Riesz regression and the covariate balancing propensity score&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20523v1</guid>
      <pubDate>Tue, 23 Dec 2025 17:14:14 +0000</pubDate>
    </item>
    <item>
      <title>Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset &amp; The Effective AAM-TSA Model</title>
      <link>http://arxiv.org/abs/2512.20548v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhiyi Duan, Xiangren Wang, Hongyu Yuan, Qianli Xing&lt;/p&gt;&lt;p&gt;Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and effi&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20548v1</guid>
      <pubDate>Tue, 23 Dec 2025 17:42:16 +0000</pubDate>
    </item>
    <item>
      <title>Information-theoretic signatures of causality in Bayesian networks and hypergraphs</title>
      <link>http://arxiv.org/abs/2512.20552v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sung En Chiang, Zhaolu Liu, Robert L. Peach, Mauricio Barahona&lt;/p&gt;&lt;p&gt;Analyzing causality in multivariate systems involves establishing how information is generated, distributed and combined, and thus requires tools that capture interactions beyond pairwise relations. Higher-order information theory provides such tools. In particular, Partial Information Decomposition (PID) allows the decomposition of the information that a set of sources provides about a target into redundant, unique, and synergistic components&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20552v1</guid>
      <pubDate>Tue, 23 Dec 2025 17:46:53 +0000</pubDate>
    </item>
    <item>
      <title>LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</title>
      <link>http://arxiv.org/abs/2512.20563v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Long Nguyen, Micha Fauth, Bernhard Jaeger, Daniel Dauner, Maximilian Igl, Andreas Geiger, Kashyap Chitta&lt;/p&gt;&lt;p&gt;Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance. Motivated by this gap, we empirically study how misalignment between privileged expert demonstrations and sensor-based student observations can limit the effectiveness of imitation learning. More precisely, experts have significantly higher visibility (e.g., ignoring occlusions) and far lower uncertainty (e.g., knowing other vehicles' actions), making them difficult to imitate reliably&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20563v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:07:43 +0000</pubDate>
    </item>
    <item>
      <title>Distilling to Hybrid Attention Models via KL-Guided Layer Selection</title>
      <link>http://arxiv.org/abs/2512.20569v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim&lt;/p&gt;&lt;p&gt;Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention variants. This paper describes a simple and efficient recipe for layer selection that uses layer importance scores derived from a small amount of training on generic text data&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20569v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:12:22 +0000</pubDate>
    </item>
    <item>
      <title>Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</title>
      <link>http://arxiv.org/abs/2512.20573v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rui Pan, Zhuofu Chen, Ravi Netravali&lt;/p&gt;&lt;p&gt;Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20573v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:16:58 +0000</pubDate>
    </item>
    <item>
      <title>Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</title>
      <link>http://arxiv.org/abs/2512.20586v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah&lt;/p&gt;&lt;p&gt;Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20586v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:32:17 +0000</pubDate>
    </item>
    <item>
      <title>Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</title>
      <link>http://arxiv.org/abs/2512.20589v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; İbrahim Oğuz Çetinkaya, Sajad Khodadadian, Taylan G. Topçu&lt;/p&gt;&lt;p&gt;As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20589v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:36:07 +0000</pubDate>
    </item>
    <item>
      <title>Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs</title>
      <link>http://arxiv.org/abs/2512.20595v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dhruv Anand, Ehsan Shareghi&lt;/p&gt;&lt;p&gt;We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare rec&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20595v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:43:05 +0000</pubDate>
    </item>
    <item>
      <title>Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</title>
      <link>http://arxiv.org/abs/2512.20605v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherre, Kaitlin Maile&lt;/p&gt;&lt;p&gt;Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20605v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:51:50 +0000</pubDate>
    </item>
    <item>
      <title>LongVideoAgent: Multi-Agent Reasoning with Long Videos</title>
      <link>http://arxiv.org/abs/2512.20618v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen&lt;/p&gt;&lt;p&gt;Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.20618v1</guid>
      <pubDate>Tue, 23 Dec 2025 18:59:49 +0000</pubDate>
    </item>
  </channel>
</rss>
