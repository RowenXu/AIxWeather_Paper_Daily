<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 22 Jan 2026 03:49:29 +0000</lastBuildDate>
    <item>
      <title>How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework</title>
      <link>http://arxiv.org/abs/2601.15153v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Choro Ulan uulu, Mikhail Kulyabin, Iris Fuhrmann, Jan Joosten, Nuno Miguel Martins Pacheco, Filippos Petridis, Rebecca Johnson, Jan Bosch&lt;/p&gt;&lt;p&gt;Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15153v1</guid>
      <pubDate>Wed, 21 Jan 2026 16:23:22 +0000</pubDate>
    </item>
    <item>
      <title>Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data</title>
      <link>http://arxiv.org/abs/2601.15158v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuval Ran-Milo, Yotam Alexander, Shahar Mendel, Nadav Cohen&lt;/p&gt;&lt;p&gt;Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15158v1</guid>
      <pubDate>Wed, 21 Jan 2026 16:36:19 +0000</pubDate>
    </item>
    <item>
      <title>Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning</title>
      <link>http://arxiv.org/abs/2601.15160v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuval Kansal, Niraj K. Jha&lt;/p&gt;&lt;p&gt;Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15160v1</guid>
      <pubDate>Wed, 21 Jan 2026 16:38:59 +0000</pubDate>
    </item>
    <item>
      <title>Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems</title>
      <link>http://arxiv.org/abs/2601.15161v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yinzhu Chen, Abdine Maiga, Hossein A. Rahmani, Emine Yilmaz&lt;/p&gt;&lt;p&gt;Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15161v1</guid>
      <pubDate>Wed, 21 Jan 2026 16:40:41 +0000</pubDate>
    </item>
    <item>
      <title>V-CAGE: Context-Aware Generation and Verification for Scalable Long-Horizon Embodied Tasks</title>
      <link>http://arxiv.org/abs/2601.15164v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yaru Liu, Ao-bo Wang, Nanyang Ye&lt;/p&gt;&lt;p&gt;Learning long-horizon embodied behaviors from synthetic data remains challenging because generated scenes are often physically implausible, language-driven programs frequently "succeed" without satisfying task semantics, and high-level instructions require grounding into executable action sequences. To address these limitations, we introduce V-CAGE, a closed-loop framework for generating robust, semantically aligned manipulation datasets at scale. First, we propose a context-aware instantiation mechanism that enforces geometric consistency during scene synthesis&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15164v1</guid>
      <pubDate>Wed, 21 Jan 2026 16:41:51 +0000</pubDate>
    </item>
    <item>
      <title>The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models</title>
      <link>http://arxiv.org/abs/2601.15165v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zanlin Ni, Shenzhi Wang, Yang Yue, Tianyu Yu, Weilin Zhao, Yeguo Hua, Tianyi Chen, Jun Song&lt;/p&gt;&lt;p&gt;Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have leveraged reinforcement learning (RL) to elicit the reasoning capability of dLLMs&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15165v1</guid>
      <pubDate>Wed, 21 Jan 2026 16:41:58 +0000</pubDate>
    </item>
    <item>
      <title>Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks</title>
      <link>http://arxiv.org/abs/2601.15177v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Lorenzo Fernández Maimó, Alberto Huertas Celdrán, Manuel Gil Pérez, Félix J. García Clemente, Gregorio Martínez Pérez&lt;/p&gt;&lt;p&gt;Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect netw&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15177v1</guid>
      <pubDate>Wed, 21 Jan 2026 16:54:19 +0000</pubDate>
    </item>
    <item>
      <title>Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback</title>
      <link>http://arxiv.org/abs/2601.15188v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Stephan Wallraven, Tim Köhne, Hartmut Westenberger, Andreas Moser&lt;/p&gt;&lt;p&gt;This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15188v1</guid>
      <pubDate>Wed, 21 Jan 2026 17:06:41 +0000</pubDate>
    </item>
    <item>
      <title>Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub</title>
      <link>http://arxiv.org/abs/2601.15195v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ramtin Ehsani, Sakshi Pathak, Shriya Rawal, Abdullah Al Mujahid, Mia Mohammad Imran, Preetha Chatterjee&lt;/p&gt;&lt;p&gt;AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five coding agents across GitHub&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15195v1</guid>
      <pubDate>Wed, 21 Jan 2026 17:12:46 +0000</pubDate>
    </item>
    <item>
      <title>BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries</title>
      <link>http://arxiv.org/abs/2601.15197v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shijie Lian, Bin Yu, Xiaopeng Lin, Laurence T. Yang, Zhaolong Shen, Changti Wu, Yuzhuo Miao, Cong Huang&lt;/p&gt;&lt;p&gt;Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15197v1</guid>
      <pubDate>Wed, 21 Jan 2026 17:15:22 +0000</pubDate>
    </item>
    <item>
      <title>Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface</title>
      <link>http://arxiv.org/abs/2601.15209v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Paige S. DeVries, Michaela Okosi, Ming Li, Nora Dunphy. Gidey Gezae, Dante Conway, Abraham Glasser, Raja Kushalnagar, Christian Vogler&lt;/p&gt;&lt;p&gt;We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken English; with Alexa's automatic speech recognition and a Wizard-of-Oz setting with a trained facilitator re-speaking commands against that of a large language model (LLM)-assisted touch interface in a mix&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15209v1</guid>
      <pubDate>Wed, 21 Jan 2026 17:33:00 +0000</pubDate>
    </item>
    <item>
      <title>Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification</title>
      <link>http://arxiv.org/abs/2601.15235v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Fabi Nahian Madhurja, Rusab Sarmun, Muhammad E. H. Chowdhury, Adam Mushtak, Israa Al-Hashimi, Sohaib Bassam Zoghoul&lt;/p&gt;&lt;p&gt;Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15235v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:15:47 +0000</pubDate>
    </item>
    <item>
      <title>Multi-context principal component analysis</title>
      <link>http://arxiv.org/abs/2601.15239v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kexin Wang, Salil Bhate, João M. Pereira, Joe Kileel, Matylda Figlerowicz, Anna Seigal&lt;/p&gt;&lt;p&gt;Principal component analysis (PCA) is a tool to capture factors that explain variation in data. Across domains, data are now collected across multiple contexts (for example, individuals with different diseases, cells of different types, or words across texts). While the factors explaining variation in data are undoubtedly shared across subsets of contexts, no tools currently exist to systematically recover such factors&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15239v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:24:32 +0000</pubDate>
    </item>
    <item>
      <title>Feasibility Preservation under Monotone Retrieval Truncation</title>
      <link>http://arxiv.org/abs/2601.15241v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sean Plummer&lt;/p&gt;&lt;p&gt;Retrieval-based systems approximate access to a corpus by exposing only a truncated subset of available evidence. Even when relevant information exists in the corpus, truncation can prevent compatible evidence from co-occurring, leading to failures that are not captured by relevance-based evaluation. This paper studies retrieval from a structural perspective, modeling query answering as a feasibility problem under truncation&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15241v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:25:16 +0000</pubDate>
    </item>
    <item>
      <title>Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism</title>
      <link>http://arxiv.org/abs/2601.15249v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Garrett G. Wen, Buxin Su, Natalie Collina, Zhun Deng, Weijie Su&lt;/p&gt;&lt;p&gt;Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15249v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:30:42 +0000</pubDate>
    </item>
    <item>
      <title>Many Experiments, Few Repetitions, Unpaired Data, and Sparse Effects: Is Causal Inference Possible?</title>
      <link>http://arxiv.org/abs/2601.15254v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Felix Schur, Niklas Pfister, Peng Ding, Sach Mukherjee, Jonas Peters&lt;/p&gt;&lt;p&gt;We study the problem of estimating causal effects under hidden confounding in the following unpaired data setting: we observe some covariates $X$ and an outcome $Y$ under different experimental conditions (environments) but do not observe them jointly; we either observe $X$ or $Y$. Under appropriate regularity conditions, the problem can be cast as an instrumental variable (IV) regression with the environment acting as a (possibly high-dimensional) instrument. When there are many environments but only a few observations per environment, standard two-sample IV estimators fail to be consistent&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15254v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:36:34 +0000</pubDate>
    </item>
    <item>
      <title>Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions</title>
      <link>http://arxiv.org/abs/2601.15267v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yiran Hu, Huanghai Liu, Chong Wang, Kunran Li, Tien-Hsuan Wu, Haitao Li, Xinran Xu, Siqing Huo&lt;/p&gt;&lt;p&gt;Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoning processes and trustworthy issues such as fairness and reliability. Systematic evaluation of LLM performance in legal tasks has therefore become essential for their responsible adoption&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15267v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:51:37 +0000</pubDate>
    </item>
    <item>
      <title>MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs</title>
      <link>http://arxiv.org/abs/2601.15279v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Christoph Bartmann, Johannes Schimunek, Mykyta Ielanskyi, Philipp Seidl, Günter Klambauer, Sohvi Luukkonen&lt;/p&gt;&lt;p&gt;A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15279v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:58:01 +0000</pubDate>
    </item>
    <item>
      <title>Rethinking Video Generation Model for the Embodied World</title>
      <link>http://arxiv.org/abs/2601.15282v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yufan Deng, Zilin Pan, Hongyu Zhang, Xiaojie Li, Ruoqing Hu, Yufei Ding, Yiming Zou, Yan Zeng&lt;/p&gt;&lt;p&gt;Video generation models have significantly advanced embodied intelligence, unlocking new possibilities for generating diverse robot data that capture perception, reasoning, and action in the physical world. However, synthesizing high-quality videos that accurately reflect real-world robotic interactions remains challenging, and the lack of a standardized benchmark limits fair comparisons and progress. To address this gap, we introduce a comprehensive robotics benchmark, RBench, designed to evaluate robot-oriented video generation across five task domains and four distinct embodiments&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15282v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:59:18 +0000</pubDate>
    </item>
    <item>
      <title>Iterative Refinement Improves Compositional Image Generation</title>
      <link>http://arxiv.org/abs/2601.15286v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shantanu Jaiswal, Mihir Prabhudesai, Nikash Bhardwaj, Zheyang Qin, Amir Zadeh, Chuan Li, Katerina Fragkiadaki, Deepak Pathak&lt;/p&gt;&lt;p&gt;Text-to-image (T2I) models have achieved remarkable progress, yet they continue to struggle with complex prompts that require simultaneously handling multiple objects, relations, and attributes. Existing inference-time strategies, such as parallel sampling with verifiers or simply increasing denoising steps, can improve prompt alignment but remain inadequate for richly compositional settings where many constraints must be satisfied. Inspired by the success of chain-of-thought reasoning in large language models, we propose an iterative test-time strategy in which a T2I model progressively refin&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.15286v1</guid>
      <pubDate>Wed, 21 Jan 2026 18:59:40 +0000</pubDate>
    </item>
  </channel>
</rss>
