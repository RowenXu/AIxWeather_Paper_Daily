<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 04 Nov 2025 03:10:59 +0000</lastBuildDate>
    <item>
      <title>InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM Research</title>
      <link>http://arxiv.org/abs/2510.27598v2</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yunze Wu, Dayuan Fu, Weiye Si, Zhen Huang, Mohan Jiang, Keyu Li, Shijie Xia, Jie Sun&lt;/p&gt;&lt;p&gt;AI agents could accelerate scientific discovery by automating hypothesis formation, experiment design, coding, execution, and analysis, yet existing benchmarks probe narrow skills in simplified settings. To address this gap, we introduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end assessment of agents performing Large Language Model (LLM) research. It comprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss Design, Reward Design, and Scaffold Construction, which require runnable artifacts and assessment of correctness, performance, output quality, an&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2510.27598v2</guid>
      <pubDate>Mon, 03 Nov 2025 10:56:21 +0000</pubDate>
    </item>
    <item>
      <title>Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation Models</title>
      <link>http://arxiv.org/abs/2510.27629v2</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Boyi Wei, Zora Che, Nathaniel Li, Udari Madhushani Sehwag, Jasper Götting, Samira Nedungadi, Julian Michael, Summer Yue&lt;/p&gt;&lt;p&gt;Open-weight bio-foundation models present a dual-use dilemma. While holding great promise for accelerating scientific research and drug development, they could also enable bad actors to develop more deadly bioweapons. To mitigate the risk posed by these models, current approaches focus on filtering biohazardous data during pre-training&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2510.27629v2</guid>
      <pubDate>Mon, 03 Nov 2025 15:19:02 +0000</pubDate>
    </item>
    <item>
      <title>Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training</title>
      <link>http://arxiv.org/abs/2510.27630v2</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dayuan Fu, Yunze Wu, Xiaojie Cai, Lyumanshan Ye, Shijie Xia, Zhen Huang, Weiye Si, Tianze Xu&lt;/p&gt;&lt;p&gt;Large Language Model (LLM) agents have recently shown strong potential in domains such as automated coding, deep research, and graphical user interface manipulation. However, training them to succeed on long-horizon, domain-specialized tasks remains challenging. Current methods primarily fall into two categories&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2510.27630v2</guid>
      <pubDate>Mon, 03 Nov 2025 10:53:11 +0000</pubDate>
    </item>
  </channel>
</rss>
