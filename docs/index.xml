<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 22 Nov 2025 03:05:17 +0000</lastBuildDate>
    <item>
      <title>Supervised Contrastive Learning for Few-Shot AI-Generated Image Detection and Attribution</title>
      <link>http://arxiv.org/abs/2511.16541v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jaime Álvarez Urueña, David Camacho, Javier Huertas Tato&lt;/p&gt;&lt;p&gt;The rapid advancement of generative artificial intelligence has enabled the creation of synthetic images that are increasingly indistinguishable from authentic content, posing significant challenges for digital media integrity. This problem is compounded by the accelerated release cycle of novel generative models, which renders traditional detection approaches (reliant on periodic retraining) computationally infeasible and operationally impractical.   This work proposes a novel two-stage detection framework designed to address the generalization challenge inherent in synthetic image detection&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16541v1</guid>
      <pubDate>Thu, 20 Nov 2025 16:53:24 +0000</pubDate>
    </item>
    <item>
      <title>The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation</title>
      <link>http://arxiv.org/abs/2511.16543v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jiaheng Zhang, Daqiang Zhang&lt;/p&gt;&lt;p&gt;The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.   Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16543v1</guid>
      <pubDate>Thu, 20 Nov 2025 16:59:16 +0000</pubDate>
    </item>
    <item>
      <title>Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes</title>
      <link>http://arxiv.org/abs/2511.16548v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Guanchen Wu, Yuzhang Xie, Huanwei Wu, Zhe He, Hui Shao, Xiao Hu, Carl Yang&lt;/p&gt;&lt;p&gt;Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16548v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:00:46 +0000</pubDate>
    </item>
    <item>
      <title>Toward Valid Generative Clinical Trial Data with Survival Endpoints</title>
      <link>http://arxiv.org/abs/2511.16551v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Perrine Chassat, Van Tuan Nguyen, Lucas Ducrot, Emilie Lanoy, Agathe Guilloux&lt;/p&gt;&lt;p&gt;Clinical trials face mounting challenges: fragmented patient populations, slow enrollment, and unsustainable costs, particularly for late phase trials in oncology and rare diseases. While external control arms built from real-world data have been explored, a promising alternative is the generation of synthetic control arms using generative AI. A central challenge is the generation of time-to-event outcomes, which constitute primary endpoints in oncology and rare disease trials, but are difficult to model under censoring and small sample sizes&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16551v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:03:38 +0000</pubDate>
    </item>
    <item>
      <title>Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation</title>
      <link>http://arxiv.org/abs/2511.16577v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kexin Zhao, Ken Forbus&lt;/p&gt;&lt;p&gt;Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16577v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:32:15 +0000</pubDate>
    </item>
    <item>
      <title>Formal Abductive Latent Explanations for Prototype-Based Networks</title>
      <link>http://arxiv.org/abs/2511.16588v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jules Soria, Zakaria Chihani, Julien Girard-Satabin, Alban Grastien, Romain Xu-Darme, Daniela Cancila&lt;/p&gt;&lt;p&gt;Case-based reasoning networks are machine-learning models that make predictions based on similarity between the input and prototypical parts of training samples, called prototypes. Such models are able to explain each decision by pointing to the prototypes that contributed the most to the final outcome. As the explanation is a core part of the prediction, they are often qualified as ``interpretable by design"&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16588v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:42:41 +0000</pubDate>
    </item>
    <item>
      <title>Green Resilience of Cyber-Physical Systems: Doctoral Dissertation</title>
      <link>http://arxiv.org/abs/2511.16593v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Diaeddin Rimawi&lt;/p&gt;&lt;p&gt;Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16593v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:46:41 +0000</pubDate>
    </item>
    <item>
      <title>TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2511.16595v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Boshen Xu, Zihan Xiao, Jiaze Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Qin Jin&lt;/p&gt;&lt;p&gt;We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16595v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:48:21 +0000</pubDate>
    </item>
    <item>
      <title>You Only Forward Once: An Efficient Compositional Judging Paradigm</title>
      <link>http://arxiv.org/abs/2511.16600v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tianlong Zhang, Hongwei Xue, Shilin Yan, Di Wu, Chen Xu, Yunyun Yang&lt;/p&gt;&lt;p&gt;Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16600v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:55:21 +0000</pubDate>
    </item>
    <item>
      <title>Time dependent loss reweighting for flow matching and diffusion models is theoretically justified</title>
      <link>http://arxiv.org/abs/2511.16599v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Lukas Billera, Hedwig Nora Nordlinder, Ben Murrell&lt;/p&gt;&lt;p&gt;This brief note clarifies that, in Generator Matching (which subsumes a large family of flow matching and diffusion models over continuous, manifold, and discrete spaces), both the Bregman divergence loss and the linear parameterization of the generator can depend on both the current state $X_t$ and the time $t$, and we show that the expectation over time in the loss can be taken with respect to a broad class of time distributions. We also show this for Edit Flows, which falls outside of Generator Matching. That the loss can depend on $t$ clarifies that time-dependent loss weighting schemes, o&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16599v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:55:21 +0000</pubDate>
    </item>
    <item>
      <title>Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization</title>
      <link>http://arxiv.org/abs/2511.16602v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yi Zhang, Che Liu, Xiancong Ren, Hanchu Ni, Yingji Zhang, Shuai Zhang, Zeyuan Ding, Jiayu Hu&lt;/p&gt;&lt;p&gt;Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted r&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16602v1</guid>
      <pubDate>Thu, 20 Nov 2025 17:58:04 +0000</pubDate>
    </item>
    <item>
      <title>Rate-optimal community detection near the KS threshold via node-robust algorithms</title>
      <link>http://arxiv.org/abs/2511.16613v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jingqiu Ding, Yiding Hua, Kasper Lindberg, David Steurer, Aleksandr Storozhenko&lt;/p&gt;&lt;p&gt;We study community detection in the \emph{symmetric $k$-stochastic block model}, where $n$ nodes are evenly partitioned into $k$ clusters with intra- and inter-cluster connection probabilities $p$ and $q$, respectively.   Our main result is a polynomial-time algorithm that achieves the minimax-optimal misclassification rate   \begin{equation*}   \exp \Bigl(-\bigl(1 \pm o(1)\bigr) \tfrac{C}{k}\Bigr),   \quad \text{where } C = (\sqrt{pn} - \sqrt{qn})^2,   \end{equation*}   whenever $C \ge K\,k^2\,\log k$ for some universal constant $K$, matching the Kesten--Stigum (KS) threshold up to a $\log k$&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16613v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:11:01 +0000</pubDate>
    </item>
    <item>
      <title>SAM 3D: 3Dfy Anything in Images</title>
      <link>http://arxiv.org/abs/2511.16624v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; SAM 3D Team, Xingyu Chen, Fu-Jen Chu, Pierre Gleize, Kevin J Liang, Alexander Sax, Hao Tang, Weiyao Wang&lt;/p&gt;&lt;p&gt;We present SAM 3D, a generative model for visually grounded 3D object reconstruction, predicting geometry, texture, and layout from a single image. SAM 3D excels in natural images, where occlusion and scene clutter are common and visual recognition cues from context play a larger role. We achieve this with a human- and model-in-the-loop pipeline for annotating object shape, texture, and pose, providing visually grounded 3D reconstruction data at unprecedented scale&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16624v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:31:46 +0000</pubDate>
    </item>
    <item>
      <title>MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support</title>
      <link>http://arxiv.org/abs/2511.16625v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Elias Hossain, Md Mehedi Hasan Nipu, Maleeha Sheikh, Rajib Rana, Subash Neupane, Niloofar Yousefi&lt;/p&gt;&lt;p&gt;We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16625v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:33:12 +0000</pubDate>
    </item>
    <item>
      <title>Evolution Strategies at the Hyperscale</title>
      <link>http://arxiv.org/abs/2511.16652v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Bidipta Sarkar, Mattie Fellows, Juan Agustin Duque, Alistair Letcher, Antonio León Villares, Anya Sims, Dylan Cope, Jarek Liesen&lt;/p&gt;&lt;p&gt;We introduce Evolution Guided General Optimization via Low-rank Learning (EGGROLL), an evolution strategies (ES) algorithm designed to scale backprop-free optimization to large population sizes for modern large neural network architectures with billions of parameters. ES is a set of powerful blackbox optimisation methods that can handle non-differentiable or noisy objectives with excellent scaling potential through parallelisation. Na{ï}ve ES becomes prohibitively expensive at scale due to the computational and memory costs associated with generating matrix perturbations $E\in\mathbb{R}^{m\tim&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16652v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:56:05 +0000</pubDate>
    </item>
    <item>
      <title>Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems</title>
      <link>http://arxiv.org/abs/2511.16657v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Juan C. King, Jose M. Amigo&lt;/p&gt;&lt;p&gt;This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performa&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16657v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:58:22 +0000</pubDate>
    </item>
    <item>
      <title>Cognitive Foundations for Reasoning and Their Manifestation in LLMs</title>
      <link>http://arxiv.org/abs/2511.16660v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Priyanka Kargupta, Shuyue Stella Li, Haocheng Wang, Jinu Lee, Shan Chen, Orevaoghene Ahia, Dean Light, Thomas L. Griffiths&lt;/p&gt;&lt;p&gt;Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, an&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16660v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:59:00 +0000</pubDate>
    </item>
    <item>
      <title>Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations</title>
      <link>http://arxiv.org/abs/2511.16661v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Irmak Guzey, Haozhi Qi, Julen Urain, Changhao Wang, Jessica Yin, Krishna Bodduluri, Mike Lambeta, Lerrel Pinto&lt;/p&gt;&lt;p&gt;Learning multi-fingered robot policies from humans performing daily tasks in natural environments has long been a grand goal in the robotics community. Achieving this would mark significant progress toward generalizable robot manipulation in human environments, as it would reduce the reliance on labor-intensive robot data collection. Despite substantial efforts, progress toward this goal has been bottle-necked by the embodiment gap between humans and robots, as well as by difficulties in extracting relevant contextual and motion cues that enable learning of autonomous policies from in-the-wild&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16661v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:59:02 +0000</pubDate>
    </item>
    <item>
      <title>Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter</title>
      <link>http://arxiv.org/abs/2511.16665v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Qinghao Hu, Shang Yang, Junxian Guo, Xiaozhe Yao, Yujun Lin, Yuxian Gu, Han Cai, Chuang Gan&lt;/p&gt;&lt;p&gt;The emergence of Large Language Models (LLMs) with strong reasoning capabilities marks a significant milestone, unlocking new frontiers in complex problem-solving. However, training these reasoning models, typically using Reinforcement Learning (RL), encounters critical efficiency bottlenecks: response generation during RL training exhibits a persistent long-tail distribution, where a few very long responses dominate execution time, wasting resources and inflating costs. To address this, we propose TLT, a system that accelerates reasoning RL training losslessly by integrating adaptive speculat&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16665v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:59:25 +0000</pubDate>
    </item>
    <item>
      <title>Dataset Distillation for Pre-Trained Self-Supervised Vision Models</title>
      <link>http://arxiv.org/abs/2511.16674v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; George Cazenavette, Antonio Torralba, Vincent Sitzmann&lt;/p&gt;&lt;p&gt;The task of dataset distillation aims to find a small set of synthetic images such that training a model on them reproduces the performance of the same model trained on a much larger dataset of real samples. Existing distillation methods focus on synthesizing datasets that enable training randomly initialized models. In contrast, state-of-the-art vision approaches are increasingly building on large, pre-trained self-supervised models rather than training from scratch&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.16674v1</guid>
      <pubDate>Thu, 20 Nov 2025 18:59:57 +0000</pubDate>
    </item>
  </channel>
</rss>
