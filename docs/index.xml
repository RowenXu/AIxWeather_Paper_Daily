<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 25 Feb 2026 04:22:11 +0000</lastBuildDate>
    <item>
      <title>Adjacency Spectral Embeddings of Correlation Networks</title>
      <link>http://arxiv.org/abs/2602.21055v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Keith Levin&lt;/p&gt;&lt;p&gt;In many applications, weighted networks are constructed based on time series data: each time series is associated to a vertex and edge weights are given by pairwise correlations. The result is a network whose edge dependency structure violates the assumptions of most common network models. Nonetheless, it is common to analyze these "correlation networks" using embedding methods derived from edge-independent network models, based on a belief that the edges are approximately independent&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21055v1</guid>
      <pubDate>Tue, 24 Feb 2026 16:13:33 +0000</pubDate>
    </item>
    <item>
      <title>Tool Building as a Path to "Superintelligence"</title>
      <link>http://arxiv.org/abs/2602.21061v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; David Koplow, Tomer Galanti, Tomaso Poggio&lt;/p&gt;&lt;p&gt;The Diligent Learner framework suggests LLMs can achieve superintelligence via test-time search, provided a sufficient step-success probability $γ$. In this work, we design a benchmark to measure $γ$ on logical out-of-distribution inference. We construct a class of tasks involving GF(2) circuit reconstruction that grow more difficult with each reasoning step, and that are, from an information-theoretic standpoint, impossible to reliably solve unless the LLM carefully integrates all of the information provided&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21061v1</guid>
      <pubDate>Tue, 24 Feb 2026 16:22:10 +0000</pubDate>
    </item>
    <item>
      <title>Motivation is Something You Need</title>
      <link>http://arxiv.org/abs/2602.21064v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mehdi Acheli, Walid Gaaloul&lt;/p&gt;&lt;p&gt;This work introduces a novel training paradigm that draws from affective neuroscience. Inspired by the interplay of emotions and cognition in the human brain and more specifically the SEEKING motivational state, we design a dual-model framework where a smaller base model is trained continuously, while a larger motivated model is activated intermittently during predefined "motivation conditions". The framework mimics the emotional state of high curiosity and anticipation of reward in which broader brain regions are recruited to enhance cognitive performance&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21064v1</guid>
      <pubDate>Tue, 24 Feb 2026 16:26:52 +0000</pubDate>
    </item>
    <item>
      <title>Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2602.21072v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhangjie Xia, Yu Yang, Pan Xu&lt;/p&gt;&lt;p&gt;Off-dynamics offline reinforcement learning (RL) aims to learn a policy for a target domain using limited target data and abundant source data collected under different transition dynamics. Existing methods typically address dynamics mismatch either globally over the state space or via pointwise data filtering; these approaches can miss localized cross-domain similarities or incur high computational cost. We propose Localized Dynamics-Aware Domain Adaptation (LoDADA), which exploits localized dynamics mismatch to better reuse source data&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21072v1</guid>
      <pubDate>Tue, 24 Feb 2026 16:32:50 +0000</pubDate>
    </item>
    <item>
      <title>Probing Graph Neural Network Activation Patterns Through Graph Topology</title>
      <link>http://arxiv.org/abs/2602.21092v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Floriano Tori, Lorenzo Bini, Marco Sorbi, Stéphane Marchand-Maillet, Vincent Ginis&lt;/p&gt;&lt;p&gt;Curvature notions on graphs provide a theoretical description of graph topology, highlighting bottlenecks and denser connected regions. Artifacts of the message passing paradigm in Graph Neural Networks, such as oversmoothing and oversquashing, have been attributed to these regions. However, it remains unclear how the topology of a graph interacts with the learned preferences of GNNs&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21092v1</guid>
      <pubDate>Tue, 24 Feb 2026 16:52:36 +0000</pubDate>
    </item>
    <item>
      <title>Attention-Based SINR Estimation in User-Centric Non-Terrestrial Networks</title>
      <link>http://arxiv.org/abs/2602.21116v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Bruno De Filippo, Alessandro Guidotti, Alessandro Vanelli-Coralli&lt;/p&gt;&lt;p&gt;The signal-to-interference-plus-noise ratio (SINR) is central to performance optimization in user-centric beamforming for satellite-based non-terrestrial networks (NTNs). Its assessment either requires the transmission of dedicated pilots or relies on computing the beamforming matrix through minimum mean squared error (MMSE)-based formulations beforehand, a process that introduces significant computational overhead. In this paper, we propose a low-complexity SINR estimation framework that leverages multi-head self-attention (MHSA) to extract inter-user interference features directly from eithe&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21116v1</guid>
      <pubDate>Tue, 24 Feb 2026 17:12:36 +0000</pubDate>
    </item>
    <item>
      <title>"Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems</title>
      <link>http://arxiv.org/abs/2602.21127v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xinfeng Li, Shenyu Dai, Kelong Zheng, Yue Xiao, Gelei Deng, Wei Dong, Xiaofeng Wang&lt;/p&gt;&lt;p&gt;Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized against their human users. While extensive research focuses on agent-centric threats, human susceptibility to deception by a compromised agent remains unexplored&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21127v1</guid>
      <pubDate>Tue, 24 Feb 2026 17:23:11 +0000</pubDate>
    </item>
    <item>
      <title>An Enhanced Projection Pursuit Tree Classifier with Visual Methods for Assessing Algorithmic Improvements</title>
      <link>http://arxiv.org/abs/2602.21130v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Natalia da Silva, Dianne Cook, Eun-Kyung Lee&lt;/p&gt;&lt;p&gt;This paper presents enhancements to the projection pursuit tree classifier and visual diagnostic methods for assessing their impact in high dimensions. The original algorithm uses linear combinations of variables in a tree structure where depth is constrained to be less than the number of classes -- a limitation that proves too rigid for complex classification problems. Our extensions improve performance in multi-class settings with unequal variance-covariance structures and nonlinear class separations by allowing more splits and more flexible class groupings in the projection pursuit computat&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21130v1</guid>
      <pubDate>Tue, 24 Feb 2026 17:27:17 +0000</pubDate>
    </item>
    <item>
      <title>SOM-VQ: Topology-Aware Tokenization for Interactive Generative Models</title>
      <link>http://arxiv.org/abs/2602.21133v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alessandro Londei, Denise Lanzieri, Matteo Benati&lt;/p&gt;&lt;p&gt;Vector-quantized representations enable powerful discrete generative models but lack semantic structure in token space, limiting interpretable human control. We introduce SOM-VQ, a tokenization method that combines vector quantization with Self-Organizing Maps to learn discrete codebooks with explicit low-dimensional topology. Unlike standard VQ-VAE, SOM-VQ uses topology-aware updates that preserve neighborhood structure: nearby tokens on a learned grid correspond to semantically similar states, enabling direct geometric manipulation of the latent space&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21133v1</guid>
      <pubDate>Tue, 24 Feb 2026 17:29:04 +0000</pubDate>
    </item>
    <item>
      <title>SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery</title>
      <link>http://arxiv.org/abs/2602.21136v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; David Anugraha, Vishakh Padmakumar, Diyi Yang&lt;/p&gt;&lt;p&gt;Qualitative insights from user experiences are critical for informing product and policy decisions, but collecting such data at scale is constrained by the time and availability of experts to conduct semi-structured interviews. Recent work has explored using large language models (LLMs) to automate interviewing, yet existing systems lack a principled mechanism for balancing systematic coverage of predefined topics with adaptive exploration, or the ability to pursue follow-ups, deep dives, and emergent themes that arise organically during conversation. In this work, we formulate adaptive semi-s&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21136v1</guid>
      <pubDate>Tue, 24 Feb 2026 17:33:02 +0000</pubDate>
    </item>
    <item>
      <title>A Benchmark for Deep Information Synthesis</title>
      <link>http://arxiv.org/abs/2602.21143v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Debjit Paul, Daniel Murphy, Milan Gritta, Ronald Cardenas, Victor Prokhorov, Lena Sophia Bolliger, Aysim Toker, Roy Miles&lt;/p&gt;&lt;p&gt;Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21143v1</guid>
      <pubDate>Tue, 24 Feb 2026 17:43:32 +0000</pubDate>
    </item>
    <item>
      <title>CG-DMER: Hybrid Contrastive-Generative Framework for Disentangled Multimodal ECG Representation Learning</title>
      <link>http://arxiv.org/abs/2602.21154v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ziwei Niu, Hao Sun, Shujun Bian, Xihong Yang, Lanfen Lin, Yuxin Liu, Yueming Jin&lt;/p&gt;&lt;p&gt;Accurate interpretation of electrocardiogram (ECG) signals is crucial for diagnosing cardiovascular diseases. Recent multimodal approaches that integrate ECGs with accompanying clinical reports show strong potential, but they still face two main concerns from a modality perspective: (1) intra-modality: existing models process ECGs in a lead-agnostic manner, overlooking spatial-temporal dependencies across leads, which restricts their effectiveness in modeling fine-grained diagnostic patterns; (2) inter-modality: existing methods directly align ECG signals with clinical reports, introducing mod&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21154v1</guid>
      <pubDate>Tue, 24 Feb 2026 17:59:21 +0000</pubDate>
    </item>
    <item>
      <title>Not Just How Much, But Where: Decomposing Epistemic Uncertainty into Per-Class Contributions</title>
      <link>http://arxiv.org/abs/2602.21160v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mame Diarra Toure, David A. Stephens&lt;/p&gt;&lt;p&gt;In safety-critical classification, the cost of failure is often asymmetric, yet Bayesian deep learning summarises epistemic uncertainty with a single scalar, mutual information (MI), that cannot distinguish whether a model's ignorance involves a benign or safety-critical class. We decompose MI into a per-class vector $C_k(x)=σ_k^{2}/(2μ_k)$, with $μ_k{=}\mathbb{E}[p_k]$ and $σ_k^2{=}\mathrm{Var}[p_k]$ across posterior samples. The decomposition follows from a second-order Taylor expansion of the entropy; the $1/μ_k$ weighting corrects boundary suppression and makes $C_k$ comparable across rare&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21160v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:05:51 +0000</pubDate>
    </item>
    <item>
      <title>PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data</title>
      <link>http://arxiv.org/abs/2602.21165v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Samah Fodeh, Linhai Ma, Yan Wang, Srivani Talakokkul, Ganesh Puthiaraju, Afshan Khan, Ashley Hagaman, Sarah Lowe&lt;/p&gt;&lt;p&gt;Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale to large volumes of patient-authored messages across health systems. Existing machine learning (ML) and natural language processing (NLP) approaches provide partial solutions but often treat patient-centered communication (PCC) and SDoH as separate tasks or rely on models not well suited to patient-facing language&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21165v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:10:00 +0000</pubDate>
    </item>
    <item>
      <title>NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning</title>
      <link>http://arxiv.org/abs/2602.21172v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ishaan Rawal, Shubh Gupta, Yihan Hu, Wei Zhan&lt;/p&gt;&lt;p&gt;Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \modelname (\textbf{No} \textbf{R}easoning for \textbf{D}riving)&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21172v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:17:21 +0000</pubDate>
    </item>
    <item>
      <title>XMorph: Explainable Brain Tumor Analysis Via LLM-Assisted Hybrid Deep Intelligence</title>
      <link>http://arxiv.org/abs/2602.21178v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sepehr Salem Ghahfarokhi, M. Moein Esfahani, Raj Sunderraman, Vince Calhoun, Mohammed Alser&lt;/p&gt;&lt;p&gt;Deep learning has significantly advanced automated brain tumor diagnosis, yet clinical adoption remains limited by interpretability and computational constraints. Conventional models often act as opaque ''black boxes'' and fail to quantify the complex, irregular tumor boundaries that characterize malignant growth. To address these challenges, we present XMorph, an explainable and computationally efficient framework for fine-grained classification of three prominent brain tumor types: glioma, meningioma, and pituitary tumors&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21178v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:28:08 +0000</pubDate>
    </item>
    <item>
      <title>Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training</title>
      <link>http://arxiv.org/abs/2602.21189v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Anas Barakat, Souradip Chakraborty, Khushbu Pahwa, Amrit Singh Bedi&lt;/p&gt;&lt;p&gt;Pass@k is a widely used performance metric for verifiable large language model tasks, including mathematical reasoning, code generation, and short-answer reasoning. It defines success if any of $k$ independently sampled solutions passes a verifier. This multi-sample inference metric has motivated inference-aware fine-tuning methods that directly optimize pass@$k$&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21189v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:43:08 +0000</pubDate>
    </item>
    <item>
      <title>Statistical Query Lower Bounds for Smoothed Agnostic Learning</title>
      <link>http://arxiv.org/abs/2602.21191v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ilias Diakonikolas, Daniel M. Kane&lt;/p&gt;&lt;p&gt;We study the complexity of smoothed agnostic learning, recently introduced by~\cite{CKKMS24}, in which the learner competes with the best classifier in a target class under slight Gaussian perturbations of the inputs. Specifically, we focus on the prototypical task of agnostically learning halfspaces under subgaussian distributions in the smoothed model. The best known upper bound for this problem relies on $L_1$-polynomial regression and has complexity $d^{\tilde{O}(1/σ^2) \log(1/ε)}$, where $σ$ is the smoothing parameter and $ε$ is the excess error&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21191v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:46:46 +0000</pubDate>
    </item>
    <item>
      <title>Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs</title>
      <link>http://arxiv.org/abs/2602.21198v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yining Hong, Huang Huang, Manling Li, Li Fei-Fei, Jiajun Wu, Yejin Choi&lt;/p&gt;&lt;p&gt;Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: \textit{reflection-in-action}, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and \textit{reflection-on-action}, which uses test-time training to update b&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21198v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:55:18 +0000</pubDate>
    </item>
    <item>
      <title>Test-Time Training with KV Binding Is Secretly Linear Attention</title>
      <link>http://arxiv.org/abs/2602.21204v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Junchen Liu, Sven Elflein, Or Litany, Zan Gojcic, Ruilong Li&lt;/p&gt;&lt;p&gt;Test-time training (TTT) with KV binding as sequence modeling layer is commonly interpreted as a form of online meta-learning that memorizes a key-value mapping at test time. However, our analysis reveals multiple phenomena that contradict this memorization-based interpretation. Motivated by these findings, we revisit the formulation of TTT and show that a broad class of TTT architectures can be expressed as a form of learned linear attention operator&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.21204v1</guid>
      <pubDate>Tue, 24 Feb 2026 18:59:30 +0000</pubDate>
    </item>
  </channel>
</rss>
