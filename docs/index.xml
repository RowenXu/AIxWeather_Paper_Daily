<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 24 Feb 2026 04:20:37 +0000</lastBuildDate>
    <item>
      <title>StructXLIP: Enhancing Vision-language Models with Multimodal Structural Cues</title>
      <link>http://arxiv.org/abs/2602.20089v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zanxi Ruan, Qiuyu Kong, Songqun Gao, Yiming Wang, Marco Cristani&lt;/p&gt;&lt;p&gt;Edge-based representations are fundamental cues for visual understanding, a principle rooted in early vision research and still central today. We extend this principle to vision-language alignment, showing that isolating and aligning structural cues across modalities can greatly benefit fine-tuning on long, detail-rich captions, with a specific focus on improving cross-modal retrieval. We introduce StructXLIP, a fine-tuning alignment paradigm that extracts edge maps (e.g., Canny), treating them as proxies for the visual structure of an image, and filters the corresponding captions to emphasize&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20089v1</guid>
      <pubDate>Mon, 23 Feb 2026 17:57:37 +0000</pubDate>
    </item>
    <item>
      <title>CausalFlip: A Benchmark for LLM Causal Judgment Beyond Semantic Matching</title>
      <link>http://arxiv.org/abs/2602.20094v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuzhe Wang, Yaochen Zhu, Jundong Li&lt;/p&gt;&lt;p&gt;As large language models (LLMs) witness increasing deployment in complex, high-stakes decision-making scenarios, it becomes imperative to ground their reasoning in causality rather than spurious correlations. However, strong performance on traditional reasoning benchmarks does not guarantee true causal reasoning ability of LLMs, as high accuracy may still arise from memorizing semantic patterns instead of analyzing the underlying true causal structures. To bridge this critical gap, we propose a new causal reasoning benchmark, CausalFlip, designed to encourage the development of new LLM paradig&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20094v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:06:15 +0000</pubDate>
    </item>
    <item>
      <title>Transcending the Annotation Bottleneck: AI-Powered Discovery in Biology and Medicine</title>
      <link>http://arxiv.org/abs/2602.20100v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Soumick Chatterjee&lt;/p&gt;&lt;p&gt;The dependence on expert annotation has long constituted the primary rate-limiting step in the application of artificial intelligence to biomedicine. While supervised learning drove the initial wave of clinical algorithms, a paradigm shift towards unsupervised and self-supervised learning (SSL) is currently unlocking the latent potential of biobank-scale datasets. By learning directly from the intrinsic structure of data - whether pixels in a magnetic resonance image (MRI), voxels in a volumetric scan, or tokens in a genomic sequence - these methods facilitate the discovery of novel phenotypes&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20100v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:15:30 +0000</pubDate>
    </item>
    <item>
      <title>BarrierSteer: LLM Safety via Learning Barrier Steering</title>
      <link>http://arxiv.org/abs/2602.20102v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Thanh Q. Tran, Arun Verma, Kiwan Wong, Bryan Kian Hsiang Low, Daniela Rus, Wei Xiao&lt;/p&gt;&lt;p&gt;Despite the state-of-the-art performance of large language models (LLMs) across diverse tasks, their susceptibility to adversarial attacks and unsafe content generation remains a major obstacle to deployment, particularly in high-stakes settings. Addressing this challenge requires safety mechanisms that are both practically effective and supported by rigorous theory. We introduce BarrierSteer, a novel framework that formalizes response safety by embedding learned non-linear safety constraints directly into the model's latent representation space&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20102v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:19:46 +0000</pubDate>
    </item>
    <item>
      <title>Align When They Want, Complement When They Need! Human-Centered Ensembles for Adaptive Human-AI Collaboration</title>
      <link>http://arxiv.org/abs/2602.20104v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hasan Amin, Ming Yin, Rajiv Khanna&lt;/p&gt;&lt;p&gt;In human-AI decision making, designing AI that complements human expertise has been a natural strategy to enhance human-AI collaboration, yet it often comes at the cost of decreased AI performance in areas of human strengths. This can inadvertently erode human trust and cause them to ignore AI advice precisely when it is most needed. Conversely, an aligned AI fosters trust yet risks reinforcing suboptimal human behavior and lowering human-AI team performance&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20104v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:22:58 +0000</pubDate>
    </item>
    <item>
      <title>StyleStream: Real-Time Zero-Shot Voice Style Conversion</title>
      <link>http://arxiv.org/abs/2602.20113v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yisi Liu, Nicholas Lee, Gopala Anumanchipalli&lt;/p&gt;&lt;p&gt;Voice style conversion aims to transform an input utterance to match a target speaker's timbre, accent, and emotion, with a central challenge being the disentanglement of linguistic content from style. While prior work has explored this problem, conversion quality remains limited, and real-time voice style conversion has not been addressed. We propose StyleStream, the first streamable zero-shot voice style conversion system that achieves state-of-the-art performance&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20113v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:32:59 +0000</pubDate>
    </item>
    <item>
      <title>Benchmarking Unlearning for Vision Transformers</title>
      <link>http://arxiv.org/abs/2602.20114v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kairan Zhao, Iurie Luca, Peter Triantafillou&lt;/p&gt;&lt;p&gt;Research in machine unlearning (MU) has gained strong momentum: MU is now widely regarded as a critical capability for building safe and fair AI. In parallel, research into transformer architectures for computer vision tasks has been highly successful: Increasingly, Vision Transformers (VTs) emerge as strong alternatives to CNNs. Yet, MU research for vision tasks has largely centered on CNNs, not VTs&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20114v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:33:16 +0000</pubDate>
    </item>
    <item>
      <title>ReSyn: Autonomously Scaling Synthetic Environments for Reasoning Models</title>
      <link>http://arxiv.org/abs/2602.20117v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Andre He, Nathaniel Weir, Kaj Bostrom, Allen Nie, Darion Cassel, Sam Bayless, Huzefa Rangwala&lt;/p&gt;&lt;p&gt;Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising approach for training reasoning language models (RLMs) by leveraging supervision from verifiers. Although verifier implementation is easier than solution annotation for many tasks, existing synthetic data generation methods remain largely solution-centric, while verifier-based methods rely on a few hand-crafted procedural environments. In this work, we scale RLVR by introducing ReSyn, a pipeline that generates diverse reasoning environments equipped with instance generators and verifiers, covering tasks such as co&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20117v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:34:29 +0000</pubDate>
    </item>
    <item>
      <title>NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning</title>
      <link>http://arxiv.org/abs/2602.20119v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jiahui Fu, Junyu Nan, Lingfeng Sun, Hongyu Li, Jianing Qian, Jennifer L. Barry, Kris Kitani, George Konidaris&lt;/p&gt;&lt;p&gt;Solving long-horizon tasks requires robots to integrate high-level semantic reasoning with low-level physical interaction. While vision-language models (VLMs) and video generation models can decompose tasks and imagine outcomes, they often lack the physical grounding necessary for real-world execution. We introduce NovaPlan, a hierarchical framework that unifies closed-loop VLM and video planning with geometrically grounded robot execution for zero-shot long-horizon manipulation&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20119v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:35:18 +0000</pubDate>
    </item>
    <item>
      <title>NanoKnow: How to Know What Your Language Model Knows</title>
      <link>http://arxiv.org/abs/2602.20122v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Lingwei Gu, Nour Jedidi, Jimmy Lin&lt;/p&gt;&lt;p&gt;How do large language models (LLMs) know what they know? Answering this question has been difficult because pre-training data is often a "black box" -- unknown or inaccessible. The recent release of nanochat -- a family of small LLMs with fully open pre-training data -- addresses this as it provides a transparent view into where a model's parametric knowledge comes from. Towards the goal of understanding how knowledge is encoded by LLMs, we release NanoKnow, a benchmark dataset that partitions questions from Natural Questions and SQuAD into splits based on whether their answers are present in &lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20122v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:37:49 +0000</pubDate>
    </item>
    <item>
      <title>Adaptation to Intrinsic Dependence in Diffusion Language Models</title>
      <link>http://arxiv.org/abs/2602.20126v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yunxiao Zhao, Changxiao Cai&lt;/p&gt;&lt;p&gt;Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) approaches, enabling parallel token generation beyond a rigid left-to-right order. Despite growing empirical success, the theoretical understanding of how unmasking schedules -- which specify the order and size of unmasked tokens during sampling -- affect generation quality remains limited. In this work, we introduce a distribution-agnostic unmasking schedule for DLMs that adapts to the (unknown) dependence structure of the target data distribution, without requiring any prior knowledge or &lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20126v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:41:34 +0000</pubDate>
    </item>
    <item>
      <title>To Reason or Not to: Selective Chain-of-Thought in Medical Question Answering</title>
      <link>http://arxiv.org/abs/2602.20130v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zaifu Zhan, Min Zeng, Shuang Zhou, Yiran Song, Xiaoyi Chen, Yu Hou, Yifan Wu, Yang Ruan&lt;/p&gt;&lt;p&gt;Objective: To improve the efficiency of medical question answering (MedQA) with large language models (LLMs) by avoiding unnecessary reasoning while maintaining accuracy.   Methods: We propose Selective Chain-of-Thought (Selective CoT), an inference-time strategy that first predicts whether a question requires reasoning and generates a rationale only when needed. Two open-source LLMs (Llama-3.1-8B and Qwen-2.5-7B) were evaluated on four biomedical QA benchmarks-HeadQA, MedQA-USMLE, MedMCQA, and PubMedQA&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20130v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:42:50 +0000</pubDate>
    </item>
    <item>
      <title>AdaEvolve: Adaptive LLM Driven Zeroth-Order Optimization</title>
      <link>http://arxiv.org/abs/2602.20133v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mert Cemri, Shubham Agrawal, Akshat Gupta, Shu Liu, Audrey Cheng, Qiuyang Mang, Ashwin Naren, Lutfi Eren Erdogan&lt;/p&gt;&lt;p&gt;The paradigm of automated program generation is shifting from one-shot generation to inference-time search, where Large Language Models (LLMs) function as semantic mutation operators within evolutionary loops. While effective, these systems are currently governed by static schedules that fail to account for the non-stationary dynamics of the search process. This rigidity results in substantial computational waste, as resources are indiscriminately allocated to stagnating populations while promising frontiers remain under-exploited&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20133v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:45:31 +0000</pubDate>
    </item>
    <item>
      <title>Modeling Epidemiological Dynamics Under Adversarial Data and User Deception</title>
      <link>http://arxiv.org/abs/2602.20134v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yiqi Su, Christo Kurisummoottil Thomas, Walid Saad, Bud Mishra, Naren Ramakrishnan&lt;/p&gt;&lt;p&gt;Epidemiological models increasingly rely on self-reported behavioral data such as vaccination status, mask usage, and social distancing adherence to forecast disease transmission and assess the impact of non-pharmaceutical interventions (NPIs). While such data provide valuable real-time insights, they are often subject to strategic misreporting, driven by individual incentives to avoid penalties, access benefits, or express distrust in public health authorities. To account for such human behavior, in this paper, we introduce a game-theoretic framework that models the interaction between the po&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20134v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:45:55 +0000</pubDate>
    </item>
    <item>
      <title>KNIGHT: Knowledge Graph-Driven Multiple-Choice Question Generation with Adaptive Hardness Calibration</title>
      <link>http://arxiv.org/abs/2602.20135v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mohammad Amanlou, Erfan Shafiee Moghaddam, Yasaman Amou Jafari, Mahdi Noori, Farhan Farsi, Behnam Bahrak&lt;/p&gt;&lt;p&gt;With the rise of large language models (LLMs), they have become instrumental in applications such as Retrieval-Augmented Generation (RAG). Yet evaluating these systems remains bottlenecked by the time and cost of building specialized assessment datasets. We introduce KNIGHT, an LLM-based, knowledge-graph-driven framework for generating multiple-choice question (MCQ) datasets from external sources&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20135v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:46:27 +0000</pubDate>
    </item>
    <item>
      <title>Recurrent Structural Policy Gradient for Partially Observable Mean Field Games</title>
      <link>http://arxiv.org/abs/2602.20141v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Clarisse Wibault, Johannes Forkel, Sebastian Towers, Tiphaine Wibault, Juan Duque, George Whittle, Andreas Schaab, Yucheng Yang&lt;/p&gt;&lt;p&gt;Mean Field Games (MFGs) provide a principled framework for modeling interactions in large population models: at scale, population dynamics become deterministic, with uncertainty entering only through aggregate shocks, or common noise. However, algorithmic progress has been limited since model-free methods are too high variance and exact methods scale poorly. Recent Hybrid Structural Methods (HSMs) use Monte Carlo rollouts for the common noise in combination with exact estimation of the expected return, conditioned on those samples&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20141v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:53:09 +0000</pubDate>
    </item>
    <item>
      <title>Agentic AI for Scalable and Robust Optical Systems Control</title>
      <link>http://arxiv.org/abs/2602.20144v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zehao Wang, Mingzhe Han, Wei Cheng, Yue-Kai Huang, Philip Ji, Denton Wu, Mahdi Safari, Flemming Holtorf&lt;/p&gt;&lt;p&gt;We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structured tool abstraction layer. We implement 64 standardized MCP tools across 8 representative optical devices and construct a 410-task benchmark to evaluate request understanding, role-aware responses, multi-step coordination, robustness to linguistic variation, and error handling&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20144v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:54:32 +0000</pubDate>
    </item>
    <item>
      <title>Behavior Learning (BL): Learning Hierarchical Optimization Structures from Data</title>
      <link>http://arxiv.org/abs/2602.20152v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhenyao Ma, Yue Liang, Dongxu Li&lt;/p&gt;&lt;p&gt;Inspired by behavioral science, we propose Behavior Learning (BL), a novel general-purpose machine learning framework that learns interpretable and identifiable optimization structures from data, ranging from single optimization problems to hierarchical compositions. It unifies predictive performance, intrinsic interpretability, and identifiability, with broad applicability to scientific domains involving optimization. BL parameterizes a compositional utility function built from intrinsically interpretable modular blocks, which induces a data distribution for prediction and generation&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20152v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:59:04 +0000</pubDate>
    </item>
    <item>
      <title>JUCAL: Jointly Calibrating Aleatoric and Epistemic Uncertainty in Classification Tasks</title>
      <link>http://arxiv.org/abs/2602.20153v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jakob Heiss, Sören Lambrecht, Jakob Weissteiner, Hanna Wutte, Žan Žurič, Josef Teichmann, Bin Yu&lt;/p&gt;&lt;p&gt;We study post-calibration uncertainty for trained ensembles of classifiers. Specifically, we consider both aleatoric (label noise) and epistemic (model) uncertainty. Among the most popular and widely used calibration methods in classification are temperature scaling (i.e., pool-then-calibrate) and conformal methods&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20153v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:59:10 +0000</pubDate>
    </item>
    <item>
      <title>A Very Big Video Reasoning Suite</title>
      <link>http://arxiv.org/abs/2602.20159v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Maijunxian Wang, Ruisi Wang, Juyi Lin, Ran Ji, Thaddäus Wiedemer, Qingying Gao, Dezhi Luo, Yaoyao Qian&lt;/p&gt;&lt;p&gt;Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.20159v1</guid>
      <pubDate>Mon, 23 Feb 2026 18:59:41 +0000</pubDate>
    </item>
  </channel>
</rss>
