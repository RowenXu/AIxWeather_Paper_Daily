<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 09 Jan 2026 03:41:03 +0000</lastBuildDate>
    <item>
      <title>VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding</title>
      <link>http://arxiv.org/abs/2601.05125v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ignacio de Rodrigo, Alvaro J. Lopez-Lopez, Jaime Boal&lt;/p&gt;&lt;p&gt;This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05125v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:15:15 +0000</pubDate>
    </item>
    <item>
      <title>Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models</title>
      <link>http://arxiv.org/abs/2601.05144v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shuliang Liu, Xingyu Li, Hongyi Liu, Yibo Yan, Bingchen Duan, Qi Zheng, Dong Fang, Lingfeng Su&lt;/p&gt;&lt;p&gt;Reasoning Large Language Models (RLLMs) excelling in complex tasks present unique challenges for digital watermarking, as existing methods often disrupt logical coherence or incur high computational costs. Token-based watermarking techniques can corrupt the reasoning flow by applying pseudo-random biases, while semantic-aware approaches improve quality but introduce significant latency or require auxiliary models. This paper introduces ReasonMark, a novel watermarking framework specifically designed for reasoning-intensive LLMs&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05144v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:32:22 +0000</pubDate>
    </item>
    <item>
      <title>Atlas 2 - Foundation models for clinical deployment</title>
      <link>http://arxiv.org/abs/2601.05148v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Maximilian Alber, Timo Milbich, Alexandra Carpen-Amarie, Stephan Tietz, Jonas Dippel, Lukas Muttenthaler, Beatriz Perez Cancer, Alessandro Benetti&lt;/p&gt;&lt;p&gt;Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model d&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05148v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:37:00 +0000</pubDate>
    </item>
    <item>
      <title>ROOFS: RObust biOmarker Feature Selection</title>
      <link>http://arxiv.org/abs/2601.05151v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Anastasiia Bakhmach, Paul Dufossé, Andrea Vaglio, Florence Monville, Laurent Greillier, Fabrice Barlési, Sébastien Benzekry&lt;/p&gt;&lt;p&gt;Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05151v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:41:07 +0000</pubDate>
    </item>
    <item>
      <title>Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms</title>
      <link>http://arxiv.org/abs/2601.05157v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alkis Kalavasis, Pravesh K. Kothari, Shuchen Li, Manolis Zampetakis&lt;/p&gt;&lt;p&gt;In this work, we give a ${\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05157v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:47:58 +0000</pubDate>
    </item>
    <item>
      <title>Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering</title>
      <link>http://arxiv.org/abs/2601.05159v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shuliang Liu, Songbo Yang, Dong Fang, Sihang Jia, Yuqi Tang, Lingfeng Su, Ruoshui Peng, Yibo Yan&lt;/p&gt;&lt;p&gt;Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitiv&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05159v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:49:13 +0000</pubDate>
    </item>
    <item>
      <title>RelayLLM: Efficient Reasoning via Collaborative Decoding</title>
      <link>http://arxiv.org/abs/2601.05167v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chengsong Huang, Tong Zheng, Langlin Huang, Jinyuan Li, Haolin Liu, Jiaxin Huang&lt;/p&gt;&lt;p&gt;Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05167v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:56:16 +0000</pubDate>
    </item>
    <item>
      <title>CoV: Chain-of-View Prompting for Spatial Reasoning</title>
      <link>http://arxiv.org/abs/2601.05172v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Haoyu Zhao, Akide Liu, Zeyu Zhang, Weijie Wang, Feng Chen, Ruihan Zhu, Gholamreza Haffari, Bohan Zhuang&lt;/p&gt;&lt;p&gt;Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05172v1</guid>
      <pubDate>Thu, 08 Jan 2026 17:59:42 +0000</pubDate>
    </item>
    <item>
      <title>FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts</title>
      <link>http://arxiv.org/abs/2601.05174v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yiji Zhao, Zihao Zhong, Ao Wang, Haomin Wen, Ming Jin, Yuxuan Liang, Huaiyu Wan, Hao Wu&lt;/p&gt;&lt;p&gt;Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05174v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:00:58 +0000</pubDate>
    </item>
    <item>
      <title>Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop</title>
      <link>http://arxiv.org/abs/2601.05184v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yaxuan Wang, Zhongteng Cai, Yujia Bao, Xueru Zhang, Yang Liu&lt;/p&gt;&lt;p&gt;The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05184v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:08:15 +0000</pubDate>
    </item>
    <item>
      <title>SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2601.05187v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yanchang Liang, Xiaowei Zhao&lt;/p&gt;&lt;p&gt;Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05187v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:10:35 +0000</pubDate>
    </item>
    <item>
      <title>Mechanisms of Prompt-Induced Hallucination in Vision-Language Models</title>
      <link>http://arxiv.org/abs/2601.05201v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; William Rudman, Michal Golovanevsky, Dana Arad, Yonatan Belinkov, Ritambhara Singh, Carsten Eickhoff, Kyle Mahowald&lt;/p&gt;&lt;p&gt;Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05201v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:23:03 +0000</pubDate>
    </item>
    <item>
      <title>Stock Market Price Prediction using Neural Prophet with Deep Neural Network</title>
      <link>http://arxiv.org/abs/2601.05202v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Navin Chhibber, Suneel Khemka, Navneet Kumar Tyagi, Rohit Tewari, Bireswar Banerjee, Piyush Ranjan&lt;/p&gt;&lt;p&gt;Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05202v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:24:22 +0000</pubDate>
    </item>
    <item>
      <title>Internal Representations as Indicators of Hallucinations in Agent Tool Selection</title>
      <link>http://arxiv.org/abs/2601.05214v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kait Healy, Bharathi Srinivasan, Visakh Madathil, Jing Wu&lt;/p&gt;&lt;p&gt;Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05214v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:38:45 +0000</pubDate>
    </item>
    <item>
      <title>CAOS: Conformal Aggregation of One-Shot Predictors</title>
      <link>http://arxiv.org/abs/2601.05219v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Maja Waldron&lt;/p&gt;&lt;p&gt;One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05219v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:44:21 +0000</pubDate>
    </item>
    <item>
      <title>Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data</title>
      <link>http://arxiv.org/abs/2601.05227v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; James Rice&lt;/p&gt;&lt;p&gt;I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and gener&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05227v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:53:59 +0000</pubDate>
    </item>
    <item>
      <title>Learning Latent Action World Models In The Wild</title>
      <link>http://arxiv.org/abs/2601.05230v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Quentin Garrido, Tushar Nagarajan, Basile Terver, Nicolas Ballas, Yann LeCun, Michael Rabbat&lt;/p&gt;&lt;p&gt;Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05230v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:55:39 +0000</pubDate>
    </item>
    <item>
      <title>Robust Reasoning as a Symmetry-Protected Topological Phase</title>
      <link>http://arxiv.org/abs/2601.05240v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ilmo Sung&lt;/p&gt;&lt;p&gt;Large language models suffer from "hallucinations"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a "Metric Phase," where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05240v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:58:34 +0000</pubDate>
    </item>
    <item>
      <title>RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation</title>
      <link>http://arxiv.org/abs/2601.05241v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Boyang Wang, Haoran Zhang, Shujie Zhang, Jinkun Hao, Mingda Jia, Qi Lv, Yucheng Mao, Zhaoyang Lyu&lt;/p&gt;&lt;p&gt;The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05241v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:59:22 +0000</pubDate>
    </item>
    <item>
      <title>GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization</title>
      <link>http://arxiv.org/abs/2601.05242v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shih-Yang Liu, Xin Dong, Ximing Lu, Shizhe Diao, Peter Belcak, Mingjie Liu, Min-Hung Chen, Hongxu Yin&lt;/p&gt;&lt;p&gt;As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.05242v1</guid>
      <pubDate>Thu, 08 Jan 2026 18:59:24 +0000</pubDate>
    </item>
  </channel>
</rss>
