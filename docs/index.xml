<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 12 Feb 2026 04:25:51 +0000</lastBuildDate>
    <item>
      <title>ContactGaussian-WM: Learning Physics-Grounded World Model from Videos</title>
      <link>http://arxiv.org/abs/2602.11021v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Meizhong Wang, Wanxin Jin, Kun Cao, Lihua Xie, Yiguang Hong&lt;/p&gt;&lt;p&gt;Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appe&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11021v1</guid>
      <pubDate>Wed, 11 Feb 2026 16:48:13 +0000</pubDate>
    </item>
    <item>
      <title>Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting</title>
      <link>http://arxiv.org/abs/2602.11024v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rishikesh Bhyri, Brian R Quaranto, Philip J Seger, Kaity Tung, Brendan Fox, Gene Yang, Steven D. Schwaitzberg, Junsong Yuan&lt;/p&gt;&lt;p&gt;Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scenarios where instruments are tightly clustered. To address this problem, we introduce Chain-of-Look, a novel visual reasoning framework that mimics the sequential human counting process by enforcing a structured visual chain, rather than relying on classic object detection which is unordered&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11024v1</guid>
      <pubDate>Wed, 11 Feb 2026 16:49:37 +0000</pubDate>
    </item>
    <item>
      <title>Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study</title>
      <link>http://arxiv.org/abs/2602.11028v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Artsvik Avetisyan, Sachin Kumar&lt;/p&gt;&lt;p&gt;Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches.   Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned text, a part-of-speech (POS)-enhanced representation combining lexical and grammatical information, and a POS-only syntactic representation&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11028v1</guid>
      <pubDate>Wed, 11 Feb 2026 16:53:57 +0000</pubDate>
    </item>
    <item>
      <title>Language Model Inversion through End-to-End Differentiation</title>
      <link>http://arxiv.org/abs/2602.11044v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kevin Yandoka Denamganaï, Kartic Subr&lt;/p&gt;&lt;p&gt;Despite emerging research on Language Models (LM), few approaches analyse the invertibility of LMs. That is, given a LM and a desirable target output sequence of tokens, determining what input prompts would yield the target output remains an open problem. We formulate this problem as a classical gradient-based optimisation&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11044v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:14:41 +0000</pubDate>
    </item>
    <item>
      <title>A Gibbs posterior sampler for inverse problem based on prior diffusion model</title>
      <link>http://arxiv.org/abs/2602.11059v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jean-François Giovannelli&lt;/p&gt;&lt;p&gt;This paper addresses the issue of inversion in cases where (1) the observation system is modeled by a linear transformation and additive noise, (2) the problem is ill-posed and regularization is introduced in a Bayesian framework by an a prior density, and (3) the latter is modeled by a diffusion process adjusted on an available large set of examples. In this context, it is known that the issue of posterior sampling is a thorny one. This paper introduces a Gibbs algorithm&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11059v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:28:11 +0000</pubDate>
    </item>
    <item>
      <title>Conversational Behavior Modeling Foundation Model With Multi-Level Perception</title>
      <link>http://arxiv.org/abs/2602.11065v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dingkun Zhou, Shuchang Pan, Jiachen Lian, Siddharth Banerjee, Sarika Pasumarthy, Dhruv Hebbar, Siddhant Patel, Zeyi Austin Li&lt;/p&gt;&lt;p&gt;Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this perceptual pathway is key to building natural full-duplex interactive systems. We introduce a framework that models this process as multi-level perception, and then reasons over conversational behaviors via a Graph-of-Thoughts (GoT)&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11065v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:32:52 +0000</pubDate>
    </item>
    <item>
      <title>Chatting with Images for Introspective Visual Thinking</title>
      <link>http://arxiv.org/abs/2602.11073v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Junfei Wu, Jian Guan, Qiang Liu, Shu Wu, Liang Wang, Wei Wu, Tienie Tan&lt;/p&gt;&lt;p&gt;Current large vision-language models (LVLMs) typically rely on text-only reasoning based on a single-pass visual encoding, which often leads to loss of fine-grained visual information. Recently the proposal of ''thinking with images'' attempts to alleviate this limitation by manipulating images via external tools or code; however, the resulting visual states are often insufficiently grounded in linguistic semantics, impairing effective cross-modal alignment - particularly when visual semantics or geometric relationships must be reasoned over across distant regions or multiple images. To addres&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11073v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:42:37 +0000</pubDate>
    </item>
    <item>
      <title>In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution</title>
      <link>http://arxiv.org/abs/2602.11079v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Frank Xiao, Santiago Aranguri&lt;/p&gt;&lt;p&gt;We propose activation-based data attribution, a method that traces behavioral changes in post-trained language models to responsible training datapoints. By computing activation-difference vectors for both test prompts and preference pairs and ranking by cosine similarity, we identify datapoints that cause specific behaviors and validate these attributions causally by retraining with modified data. Clustering behavior-datapoint similarity matrices also enables unsupervised discovery of emergent behaviors&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11079v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:45:31 +0000</pubDate>
    </item>
    <item>
      <title>SteuerLLM: Local specialized large language model for German tax law analysis</title>
      <link>http://arxiv.org/abs/2602.11081v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sebastian Wind, Jeta Sopa, Laurin Schmid, Quirin Jackl, Sebastian Kiefer, Fei Wu, Martin Mayr, Harald Köstler&lt;/p&gt;&lt;p&gt;Large language models (LLMs) demonstrate strong general reasoning and language understanding, yet their performance degrades in domains governed by strict formal rules, precise terminology, and legally binding structure. Tax law exemplifies these challenges, as correct answers require exact statutory citation, structured legal argumentation, and numerical accuracy under rigid grading schemes. We algorithmically generate SteuerEx, the first open benchmark derived from authentic German university tax law examinations&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11081v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:46:01 +0000</pubDate>
    </item>
    <item>
      <title>GRASP: group-Shapley feature selection for patients</title>
      <link>http://arxiv.org/abs/2602.11084v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuheng Luo, Shuyan Li, Zhong Cao&lt;/p&gt;&lt;p&gt;Feature selection remains a major challenge in medical prediction, where existing approaches such as LASSO often lack robustness and interpretability. We introduce GRASP, a novel framework that couples Shapley value driven attribution with group $L_{21}$ regularization to extract compact and non-redundant feature sets. GRASP first distills group level importance scores from a pretrained tree model via SHAP, then enforces structured sparsity through group $L_{21}$ regularized logistic regression, yielding stable and interpretable selections&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11084v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:50:57 +0000</pubDate>
    </item>
    <item>
      <title>General Flexible $f$-divergence for Challenging Offline RL Datasets with Low Stochasticity and Diverse Behavior Policies</title>
      <link>http://arxiv.org/abs/2602.11087v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jianxun Wang, Grant C. Forbes, Leonardo Villalobos-Arias, David L. Roberts&lt;/p&gt;&lt;p&gt;Offline RL algorithms aim to improve upon the behavior policy that produces the collected data while constraining the learned policy to be within the support of the dataset. However, practical offline datasets often contain examples with little diversity or limited exploration of the environment, and from multiple behavior policies with diverse expertise levels. Limited exploration can impair the offline RL algorithm's ability to estimate \textit{Q} or \textit{V} values, while constraining towards diverse behavior policies can be overly conservative&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11087v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:53:49 +0000</pubDate>
    </item>
    <item>
      <title>DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2602.11089v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yicheng Chen, Zerun Ma, Xinchen Xie, Yining Li, Kai Chen&lt;/p&gt;&lt;p&gt;In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the \emph{data recipe}, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11089v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:56:15 +0000</pubDate>
    </item>
    <item>
      <title>Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates</title>
      <link>http://arxiv.org/abs/2602.11090v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Carlos Stein Brito&lt;/p&gt;&lt;p&gt;Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post hoc calibration. Cross-regularized uncertainty learns uncertainty parameters during training using gradients routed through a held-out regularization split&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11090v1</guid>
      <pubDate>Wed, 11 Feb 2026 17:57:20 +0000</pubDate>
    </item>
    <item>
      <title>Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away</title>
      <link>http://arxiv.org/abs/2602.11096v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Soumya Suvra Ghosal, Souradip Chakraborty, Vaibhav Singh, Furong Huang, Dinesh Manocha, Amrit Singh Bedi&lt;/p&gt;&lt;p&gt;Reinforcement learning (RL) based post-training for explicit chain-of-thought (e.g., GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose SafeThink, a lightweight inference-time defense that treats safety recovery as a satisficing constraint rather than a maximization objective&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11096v1</guid>
      <pubDate>Wed, 11 Feb 2026 18:09:17 +0000</pubDate>
    </item>
    <item>
      <title>A Doubly Robust Machine Learning Approach for Disentangling Treatment Effect Heterogeneity with Functional Outcomes</title>
      <link>http://arxiv.org/abs/2602.11118v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Filippo Salmaso, Lorenzo Testa, Francesca Chiaromonte&lt;/p&gt;&lt;p&gt;Causal inference is paramount for understanding the effects of interventions, yet extracting personalized insights from increasingly complex data remains a significant challenge for modern machine learning. This is the case, in particular, when considering functional outcomes observed over a continuous domain (e.g., time, or space). Estimation of heterogeneous treatment effects, known as CATE, has emerged as a crucial tool for personalized decision-making, but existing meta-learning frameworks are largely limited to scalar outcomes, failing to provide satisfying results in scientific applicati&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11118v1</guid>
      <pubDate>Wed, 11 Feb 2026 18:31:59 +0000</pubDate>
    </item>
    <item>
      <title>FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight</title>
      <link>http://arxiv.org/abs/2602.11136v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jiayi Zhou, Yang Sheng, Hantao Lou, Yaodong Yang, Jie Fu&lt;/p&gt;&lt;p&gt;As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing &lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11136v1</guid>
      <pubDate>Wed, 11 Feb 2026 18:48:11 +0000</pubDate>
    </item>
    <item>
      <title>Weight Decay Improves Language Model Plasticity</title>
      <link>http://arxiv.org/abs/2602.11137v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tessa Han, Sebastian Bordt, Hanlin Zhang, Sham Kakade&lt;/p&gt;&lt;p&gt;The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimization and scaling laws have been studied primarily from the perspective of the base model's validation loss, ignoring downstream adaptability. In this work, we study pretraining from the perspective of model plasticity, that is, the ability of the base model to successfully adapt to downstream tasks through fine-tuning&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11137v1</guid>
      <pubDate>Wed, 11 Feb 2026 18:49:26 +0000</pubDate>
    </item>
    <item>
      <title>Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows</title>
      <link>http://arxiv.org/abs/2602.11142v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shaswat Garg, Matin Moezzi, Brandon Da Silva&lt;/p&gt;&lt;p&gt;Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11142v1</guid>
      <pubDate>Wed, 11 Feb 2026 18:54:48 +0000</pubDate>
    </item>
    <item>
      <title>GENIUS: Generative Fluid Intelligence Evaluation Suite</title>
      <link>http://arxiv.org/abs/2602.11144v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ruichuan An, Sihan Yang, Ziyu Guo, Wei Dai, Zijun Shen, Haodong Li, Renrui Zhang, Xinyu Wei&lt;/p&gt;&lt;p&gt;Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess $\textit{Crystallized Intelligence}$, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks $\textit{Generative Fluid Intelligence (GFI)}$: the capacity to induce patterns, reason through constraints, and adapt to novel scenarios on the fly&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11144v1</guid>
      <pubDate>Wed, 11 Feb 2026 18:55:54 +0000</pubDate>
    </item>
    <item>
      <title>Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling</title>
      <link>http://arxiv.org/abs/2602.11146v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Gongye Liu, Bo Yang, Yida Zhi, Zhizhou Zhong, Lei Ke, Didan Deng, Han Gao, Yongxiang Huang&lt;/p&gt;&lt;p&gt;Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator through a pixel-space reward introduces a domain mismatch that complicates alignment&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.11146v1</guid>
      <pubDate>Wed, 11 Feb 2026 18:57:29 +0000</pubDate>
    </item>
  </channel>
</rss>
