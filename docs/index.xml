<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 27 Nov 2025 03:12:43 +0000</lastBuildDate>
    <item>
      <title>BAMAS: Structuring Budget-Aware Multi-Agent Systems</title>
      <link>http://arxiv.org/abs/2511.21572v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Liming Yang, Junyu Luo, Xuanzhe Liu, Yiling Lou, Zhenpeng Chen&lt;/p&gt;&lt;p&gt;Large language model (LLM)-based multi-agent systems have emerged as a powerful paradigm for enabling autonomous agents to solve complex tasks. As these systems scale in complexity, cost becomes an important consideration for practical deployment. However, existing work rarely addresses how to structure multi-agent systems under explicit budget constraints&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21572v1</guid>
      <pubDate>Wed, 26 Nov 2025 16:48:18 +0000</pubDate>
    </item>
    <item>
      <title>Multimodal Robust Prompt Distillation for 3D Point Cloud Models</title>
      <link>http://arxiv.org/abs/2511.21574v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xiang Gu, Liming Lu, Xu Zheng, Anan Du, Yongbin Zhou, Shuchao Pang&lt;/p&gt;&lt;p&gt;Adversarial attacks pose a significant threat to learning-based 3D point cloud models, critically undermining their reliability in security-sensitive applications. Existing defense methods often suffer from (1) high computational overhead and (2) poor generalization ability across diverse attack types. To bridge these gaps, we propose a novel yet efficient teacher-student framework, namely Multimodal Robust Prompt Distillation (MRPD) for distilling robust 3D point cloud model&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21574v1</guid>
      <pubDate>Wed, 26 Nov 2025 16:49:38 +0000</pubDate>
    </item>
    <item>
      <title>HarmonicAttack: An Adaptive Cross-Domain Audio Watermark Removal</title>
      <link>http://arxiv.org/abs/2511.21577v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kexin Li, Xiao Hu, Ilya Grishchenko, David Lie&lt;/p&gt;&lt;p&gt;The availability of high-quality, AI-generated audio raises security challenges such as misinformation campaigns and voice-cloning fraud. A key defense against the misuse of AI-generated audio is by watermarking it, so that it can be easily distinguished from genuine audio. As those seeking to misuse AI-generated audio may thus seek to remove audio watermarks, studying effective watermark removal techniques is critical to being able to objectively evaluate the robustness of audio watermarks against removal&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21577v1</guid>
      <pubDate>Wed, 26 Nov 2025 16:51:20 +0000</pubDate>
    </item>
    <item>
      <title>Model-Based Policy Adaptation for Closed-Loop End-to-End Autonomous Driving</title>
      <link>http://arxiv.org/abs/2511.21584v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Haohong Lin, Yunzhi Zhang, Wenhao Ding, Jiajun Wu, Ding Zhao&lt;/p&gt;&lt;p&gt;End-to-end (E2E) autonomous driving models have demonstrated strong performance in open-loop evaluations but often suffer from cascading errors and poor generalization in closed-loop settings. To address this gap, we propose Model-based Policy Adaptation (MPA), a general framework that enhances the robustness and safety of pretrained E2E driving agents during deployment. MPA first generates diverse counterfactual trajectories using a geometry-consistent simulation engine, exposing the agent to scenarios beyond the original dataset&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21584v1</guid>
      <pubDate>Wed, 26 Nov 2025 17:01:41 +0000</pubDate>
    </item>
    <item>
      <title>On the Limits of Innate Planning in Large Language Models</title>
      <link>http://arxiv.org/abs/2511.21591v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Charles Schepanowski, Charles Ling&lt;/p&gt;&lt;p&gt;Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21591v1</guid>
      <pubDate>Wed, 26 Nov 2025 17:08:13 +0000</pubDate>
    </item>
    <item>
      <title>Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining</title>
      <link>http://arxiv.org/abs/2511.21613v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dongyang Fan, Diba Hashemi, Sai Praneeth Karimireddy, Martin Jaggi&lt;/p&gt;&lt;p&gt;Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21613v1</guid>
      <pubDate>Wed, 26 Nov 2025 17:36:31 +0000</pubDate>
    </item>
    <item>
      <title>On the Origin of Algorithmic Progress in AI</title>
      <link>http://arxiv.org/abs/2511.21622v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hans Gundlach, Alex Fogelson, Jayson Lynch, Ana Trisovic, Jonathan Rosenfeld, Anmol Sandhu, Neil Thompson&lt;/p&gt;&lt;p&gt;Algorithms have been estimated to increase AI training FLOP efficiency by a factor of 22,000 between 2012 and 2023 [Ho et al., 2024]. Running small-scale ablation experiments on key innovations from this time period, we are able to account for less than 10x of these gains. Surveying the broader literature, we estimate that additional innovations not included in our ablations account for less than 10x, yielding a total under 100x&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21622v1</guid>
      <pubDate>Wed, 26 Nov 2025 17:46:31 +0000</pubDate>
    </item>
    <item>
      <title>Scale-Agnostic Kolmogorov-Arnold Geometry in Neural Networks</title>
      <link>http://arxiv.org/abs/2511.21626v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mathew Vanherreweghe, Michael H. Freedman, Keith M. Adams&lt;/p&gt;&lt;p&gt;Recent work by Freedman and Mulligan demonstrated that shallow multilayer perceptrons spontaneously develop Kolmogorov-Arnold geometric (KAG) structure during training on synthetic three-dimensional tasks. However, it remained unclear whether this phenomenon persists in realistic high-dimensional settings and what spatial properties this geometry exhibits.   We extend KAG analysis to MNIST digit classification (784 dimensions) using 2-layer MLPs with systematic spatial analysis at multiple scales&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21626v1</guid>
      <pubDate>Wed, 26 Nov 2025 17:52:05 +0000</pubDate>
    </item>
    <item>
      <title>Qwen3-VL Technical Report</title>
      <link>http://arxiv.org/abs/2511.21631v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shuai Bai, Yuxuan Cai, Ruizhe Chen, Keqin Chen, Xionghui Chen, Zesen Cheng, Lianghao Deng, Wei Ding&lt;/p&gt;&lt;p&gt;We introduce Qwen3-VL, the most capable vision-language model in the Qwen series to date, achieving superior performance across a broad range of multimodal benchmarks. It natively supports interleaved contexts of up to 256K tokens, seamlessly integrating text, images, and video. The model family includes both dense (2B/4B/8B/32B) and mixture-of-experts (30B-A3B/235B-A22B) variants to accommodate diverse latency-quality trade-offs&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21631v1</guid>
      <pubDate>Wed, 26 Nov 2025 17:59:08 +0000</pubDate>
    </item>
    <item>
      <title>Mechanisms of Non-Monotonic Scaling in Vision Transformers</title>
      <link>http://arxiv.org/abs/2511.21635v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Anantha Padmanaban Krishna Kumar&lt;/p&gt;&lt;p&gt;Deeper Vision Transformers often perform worse than shallower ones, which challenges common scaling assumptions. Through a systematic empirical analysis of ViT-S, ViT-B, and ViT-L on ImageNet, we identify a consistent three-phase Cliff-Plateau-Climb pattern that governs how representations evolve with depth. We observe that better performance is associated with progressive marginalization of the [CLS] token, originally designed as a global aggregation hub, in favor of distributed consensus among patch tokens&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21635v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:07:14 +0000</pubDate>
    </item>
    <item>
      <title>Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling</title>
      <link>http://arxiv.org/abs/2511.21636v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Peter S. Hovmand, Kari O'Donnell, Callie Ogland-Hand, Brian Biroscak, Douglas D. Gunzler&lt;/p&gt;&lt;p&gt;AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's "the unavoidable a priori")&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21636v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:08:20 +0000</pubDate>
    </item>
    <item>
      <title>Continual Error Correction on Low-Resource Devices</title>
      <link>http://arxiv.org/abs/2511.21652v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kirill Paramonov, Mete Ozay, Aristeidis Mystakidis, Nikolaos Tsalikidis, Dimitrios Sotos, Anastasios Drosou, Dimitrios Tzovaras, Hyunjun Kim&lt;/p&gt;&lt;p&gt;The proliferation of AI models in everyday devices has highlighted a critical challenge: prediction errors that degrade user experience. While existing solutions focus on error detection, they rarely provide efficient correction mechanisms, especially for resource-constrained devices. We present a novel system enabling users to correct AI misclassifications through few-shot learning, requiring minimal computational resources and storage&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21652v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:24:11 +0000</pubDate>
    </item>
    <item>
      <title>Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models</title>
      <link>http://arxiv.org/abs/2511.21663v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Naifu Zhang, Wei Tao, Xi Xiao, Qianpu Sun, Yuxin Zheng, Wentao Mo, Peiqiang Wang, Nan Zhang&lt;/p&gt;&lt;p&gt;In recent years, Vision-Language-Action (VLA) models in embodied intelligence have developed rapidly. However, existing adversarial attack methods require costly end-to-end training and often generate noticeable perturbation patches. To address these limitations, we propose ADVLA, a framework that directly applies adversarial perturbations on features projected from the visual encoder into the textual feature space&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21663v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:37:54 +0000</pubDate>
    </item>
    <item>
      <title>Escaping the Verifier: Learning to Reason via Demonstrations</title>
      <link>http://arxiv.org/abs/2511.21667v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Locke Cai, Ivan Provilkov&lt;/p&gt;&lt;p&gt;Training Large Language Models (LLMs) to reason often relies on Reinforcement Learning (RL) with task-specific verifiers. However, many real-world reasoning-intensive tasks lack verifiers, despite offering abundant expert demonstrations that remain under-utilized for reasoning-focused training. We introduce RARO (Relativistic Adversarial Reasoning Optimization) that learns strong reasoning capabilities from only expert demonstrations via Inverse Reinforcement Learning&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21667v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:42:52 +0000</pubDate>
    </item>
    <item>
      <title>Through the telecom lens: Are all training samples important?</title>
      <link>http://arxiv.org/abs/2511.21668v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shruti Bothe, Illyyne Saffar, Aurelie Boisbunon, Hasan Farooq, Julien Forgeat, Md Moin Uddin Chowdhury&lt;/p&gt;&lt;p&gt;The rise of AI in telecommunications, from optimizing Radio Access Networks to managing user experience, has sharply increased data volumes and training demands. Telecom data is often noisy, high-dimensional, costly to store, process, and label. Despite Ai's critical role, standard workflows still assume all training samples contribute equally&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21668v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:44:02 +0000</pubDate>
    </item>
    <item>
      <title>On Evolution-Based Models for Experimentation Under Interference</title>
      <link>http://arxiv.org/abs/2511.21675v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sadegh Shirani, Mohsen Bayati&lt;/p&gt;&lt;p&gt;Causal effect estimation in networked systems is central to data-driven decision making. In such settings, interventions on one unit can spill over to others, and in complex physical or social systems, the interaction pathways driving these interference structures remain largely unobserved. We argue that for identifying population-level causal effects, it is not necessary to recover the exact network structure; instead, it suffices to characterize how those interactions contribute to the evolution of outcomes&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21675v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:53:46 +0000</pubDate>
    </item>
    <item>
      <title>Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework</title>
      <link>http://arxiv.org/abs/2511.21686v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dong Wang, Yang Li, Ansong Ni, Ching-Feng Yeh, Youssef Emad, Xinjie Lei, Liam Robbins, Karthik Padthe&lt;/p&gt;&lt;p&gt;Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are hardcoded for specific domains, limiting flexibility&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21686v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:59:28 +0000</pubDate>
    </item>
    <item>
      <title>G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning</title>
      <link>http://arxiv.org/abs/2511.21688v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Wenbo Hu, Jingli Lin, Yilin Long, Yunlong Ran, Lihan Jiang, Yifan Wang, Chenming Zhu, Runsen Xu&lt;/p&gt;&lt;p&gt;Vision-Language Models (VLMs) still lack robustness in spatial intelligence, demonstrating poor performance on spatial understanding and reasoning tasks. We attribute this gap to the absence of a visual geometry learning process capable of reconstructing 3D space from 2D images. We present G$^2$VLM, a geometry grounded vision-language model that bridges two fundamental aspects of spatial intelligence: spatial 3D reconstruction and spatial understanding&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21688v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:59:39 +0000</pubDate>
    </item>
    <item>
      <title>ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration</title>
      <link>http://arxiv.org/abs/2511.21689v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hongjin Su, Shizhe Diao, Ximing Lu, Mingjie Liu, Jiacheng Xu, Xin Dong, Yonggan Fu, Peter Belcak&lt;/p&gt;&lt;p&gt;Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21689v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:59:46 +0000</pubDate>
    </item>
    <item>
      <title>Revisiting Generalization Across Difficulty Levels: It's Not So Easy</title>
      <link>http://arxiv.org/abs/2511.21692v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yeganeh Kordi, Nihal V. Nayak, Max Zuo, Ilana Nguyen, Stephen H. Bach&lt;/p&gt;&lt;p&gt;We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' generalization across models, datasets, and fine-grained groups of example difficulty&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2511.21692v1</guid>
      <pubDate>Wed, 26 Nov 2025 18:59:57 +0000</pubDate>
    </item>
  </channel>
</rss>
