<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 17 Jan 2026 03:23:46 +0000</lastBuildDate>
    <item>
      <title>causalfe: Causal Forests with Fixed Effects in Python</title>
      <link>http://arxiv.org/abs/2601.10555v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Harry Aytug&lt;/p&gt;&lt;p&gt;The causalfe package provides a Python implementation of Causal Forests with Fixed Effects (CFFE) for estimating heterogeneous treatment effects in panel data settings. Standard causal forest methods struggle with panel data because unit and time fixed effects induce spurious heterogeneity in treatment effect estimates. The CFFE approach addresses this by performing node-level residualization during tree construction, removing fixed effects within each candidate split rather than globally&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10555v1</guid>
      <pubDate>Thu, 15 Jan 2026 16:19:52 +0000</pubDate>
    </item>
    <item>
      <title>Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems</title>
      <link>http://arxiv.org/abs/2601.10560v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xi Shi, Mengxin Zheng, Qian Lou&lt;/p&gt;&lt;p&gt;Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investigate learning-based orchestration of multi-agent systems with explicit latency supervision under par&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10560v1</guid>
      <pubDate>Thu, 15 Jan 2026 16:23:53 +0000</pubDate>
    </item>
    <item>
      <title>Process-Guided Concept Bottleneck Model</title>
      <link>http://arxiv.org/abs/2601.10562v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Reza M. Asiyabi, SEOSAW Partnership, Steven Hancock, Casey Ryan&lt;/p&gt;&lt;p&gt;Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate c&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10562v1</guid>
      <pubDate>Thu, 15 Jan 2026 16:25:55 +0000</pubDate>
    </item>
    <item>
      <title>Generative AI collective behavior needs an interactionist paradigm</title>
      <link>http://arxiv.org/abs/2601.10567v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Laura Ferrarotti, Gian Maria Campedelli, Roberto Dessì, Andrea Baronchelli, Giovanni Iacca, Kathleen M. Carley, Alex Pentland, Joel Z. Leibo&lt;/p&gt;&lt;p&gt;In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical too&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10567v1</guid>
      <pubDate>Thu, 15 Jan 2026 16:29:23 +0000</pubDate>
    </item>
    <item>
      <title>From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA</title>
      <link>http://arxiv.org/abs/2601.10581v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kimia Abedini, Farzad Shami, Gianmaria Silvello&lt;/p&gt;&lt;p&gt;Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10581v1</guid>
      <pubDate>Thu, 15 Jan 2026 16:54:11 +0000</pubDate>
    </item>
    <item>
      <title>Adversarial Evasion Attacks on Computer Vision using SHAP Values</title>
      <link>http://arxiv.org/abs/2601.10587v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Frank Mollard, Marcus Becker, Florian Roehrbein&lt;/p&gt;&lt;p&gt;The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10587v1</guid>
      <pubDate>Thu, 15 Jan 2026 16:58:55 +0000</pubDate>
    </item>
    <item>
      <title>ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition</title>
      <link>http://arxiv.org/abs/2601.10591v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Arundeep Chinta, Lucas Vinh Tran, Jay Katukuri&lt;/p&gt;&lt;p&gt;Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to addr&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10591v1</guid>
      <pubDate>Thu, 15 Jan 2026 17:02:06 +0000</pubDate>
    </item>
    <item>
      <title>On the geometry of aggregate snowflakes</title>
      <link>http://arxiv.org/abs/2601.10608v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Axel Seifert, Christoph Siewert, Fabian Jakub, Leonie von Terzi, Stefan Kneifel&lt;/p&gt;&lt;p&gt;Snowflakes play a crucial role in weather and climate. A significant portion of precipitation that reaches the surface originates as ice, even when it ultimately falls as rain. Contrary to the popular image of symmetric, dendritic crystals, most large snowflakes are irregular aggregates formed through the collision of primary ice crystals, such as hexagonal plates, columns, and dendrites&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10608v1</guid>
      <pubDate>Thu, 15 Jan 2026 17:23:41 +0000</pubDate>
    </item>
    <item>
      <title>Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding</title>
      <link>http://arxiv.org/abs/2601.10611v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Christopher Clark, Jieyu Zhang, Zixian Ma, Jae Sung Park, Mohammadreza Salehi, Rohun Tripathi, Sangho Lee, Zhongzheng Ren&lt;/p&gt;&lt;p&gt;Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10611v1</guid>
      <pubDate>Thu, 15 Jan 2026 17:27:44 +0000</pubDate>
    </item>
    <item>
      <title>Differentially Private Inference for Longitudinal Linear Regression</title>
      <link>http://arxiv.org/abs/2601.10626v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Getoar Sopa, Marco Avella Medina, Cynthia Rush&lt;/p&gt;&lt;p&gt;Differential Privacy (DP) provides a rigorous framework for releasing statistics while protecting individual information present in a dataset. Although substantial progress has been made on differentially private linear regression, existing methods almost exclusively address the item-level DP setting, where each user contributes a single observation. Many scientific and economic applications instead involve longitudinal or panel data, in which each user contributes multiple dependent observations&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10626v1</guid>
      <pubDate>Thu, 15 Jan 2026 17:47:02 +0000</pubDate>
    </item>
    <item>
      <title>Parametric RDT approach to computational gap of symmetric binary perceptron</title>
      <link>http://arxiv.org/abs/2601.10628v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mihailo Stojnic&lt;/p&gt;&lt;p&gt;We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \emph{satisfiability} ($α_c$) -- \emph{algorithmic} ($α_a$) constraints density threshold change thereby suggesting a potential existence of a nonzero computational gap $SCG=α_c-α_a$. The second level estimate is shown to match the the&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10628v1</guid>
      <pubDate>Thu, 15 Jan 2026 17:48:58 +0000</pubDate>
    </item>
    <item>
      <title>Classification Imbalance as Transfer Learning</title>
      <link>http://arxiv.org/abs/2601.10630v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Eric Xia, Jason M. Klusowski&lt;/p&gt;&lt;p&gt;Classification imbalance arises when one class is much rarer than the other. We frame this setting as transfer learning under label (prior) shift between an imbalanced source distribution induced by the observed data and a balanced target distribution under which performance is evaluated. Within this framework, we study a family of oversampling procedures that augment the training data by generating synthetic samples from an estimated minority-class distribution to roughly balance the classes, among which the celebrated SMOTE algorithm is a canonical example&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10630v1</guid>
      <pubDate>Thu, 15 Jan 2026 17:49:36 +0000</pubDate>
    </item>
    <item>
      <title>Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models</title>
      <link>http://arxiv.org/abs/2601.10679v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zirui Ren, Ziming Liu&lt;/p&gt;&lt;p&gt;Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10679v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:42:50 +0000</pubDate>
    </item>
    <item>
      <title>Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems</title>
      <link>http://arxiv.org/abs/2601.10681v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Amir Khurshid, Abhishek Sehgal&lt;/p&gt;&lt;p&gt;Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10681v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:43:19 +0000</pubDate>
    </item>
    <item>
      <title>On the origin of neural scaling laws: from random graphs to natural language</title>
      <link>http://arxiv.org/abs/2601.10684v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Maissam Barkeshli, Alberto Alfarano, Andrey Gromov&lt;/p&gt;&lt;p&gt;Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10684v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:46:09 +0000</pubDate>
    </item>
    <item>
      <title>Quantum geometry of the rotating shallow water model</title>
      <link>http://arxiv.org/abs/2601.10695v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sriram Ganeshan, Alan T. Dorsey&lt;/p&gt;&lt;p&gt;The rotating shallow water equations (RSWE) are a mainstay of atmospheric and oceanic modeling, and their wave dynamics has close analogues in settings ranging from two-dimensional electron gases to active-matter fluids. While recent work has emphasized the topological character of RSWE wave bands, here we develop a complementary quantum-geometric description by computing the full quantum geometric tensor (QGT) for the linearized RSWE on an $f$-plane. The QGT unifies two pieces of band geometry: its real part defines a metric that quantifies how rapidly wave polarization changes with parameter&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10695v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:52:38 +0000</pubDate>
    </item>
    <item>
      <title>The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load</title>
      <link>http://arxiv.org/abs/2601.10696v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Han Jiang, Yao Xiao, Rachel Hurley, Shichao Liu&lt;/p&gt;&lt;p&gt;Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10696v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:52:59 +0000</pubDate>
    </item>
    <item>
      <title>LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals</title>
      <link>http://arxiv.org/abs/2601.10700v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Gilat Toker, Nitay Calderon, Ohad Amosy, Roi Reichart&lt;/p&gt;&lt;p&gt;Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10700v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:54:50 +0000</pubDate>
    </item>
    <item>
      <title>Grounding Agent Memory in Contextual Intent</title>
      <link>http://arxiv.org/abs/2601.10702v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ruozhen Yang, Yucheng Jiang, Yueqi Jiang, Priyanka Kargupta, Yunyi Zhang, Jiawei Han&lt;/p&gt;&lt;p&gt;Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step's intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10702v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:55:13 +0000</pubDate>
    </item>
    <item>
      <title>MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching</title>
      <link>http://arxiv.org/abs/2601.10712v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Changle Qu, Sunhao Dai, Hengyi Cai, Jun Xu, Shuaiqiang Wang, Dawei Yin&lt;/p&gt;&lt;p&gt;Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.10712v1</guid>
      <pubDate>Thu, 15 Jan 2026 18:59:23 +0000</pubDate>
    </item>
  </channel>
</rss>
