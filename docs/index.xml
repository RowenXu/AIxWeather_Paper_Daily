<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 26 Dec 2025 03:25:51 +0000</lastBuildDate>
    <item>
      <title>Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks</title>
      <link>http://arxiv.org/abs/2512.21241v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xinjie Xu, Shuyu Cheng, Dongwei Xu, Qi Xuan, Chen Ma&lt;/p&gt;&lt;p&gt;In hard-label black-box adversarial attacks, where only the top-1 predicted label is accessible, the prohibitive query complexity poses a major obstacle to practical deployment. In this paper, we focus on optimizing a representative class of attacks that search for the optimal ray direction yielding the minimum $\ell_2$-norm perturbation required to move a benign image into the adversarial region. Inspired by Nesterov's Accelerated Gradient (NAG), we propose a momentum-based algorithm, ARS-OPT, which proactively estimates the gradient with respect to a future ray direction inferred from accumu&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21241v1</guid>
      <pubDate>Wed, 24 Dec 2025 15:35:03 +0000</pubDate>
    </item>
    <item>
      <title>LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation</title>
      <link>http://arxiv.org/abs/2512.21243v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Anatoly O. Onishchenko, Alexey K. Kovalev, Aleksandr I. Panov&lt;/p&gt;&lt;p&gt;Methods that use Large Language Models (LLM) as planners for embodied instruction following tasks have become widespread. To successfully complete tasks, the LLM must be grounded in the environment in which the robot operates. One solution is to use a scene graph that contains all the necessary information&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21243v1</guid>
      <pubDate>Wed, 24 Dec 2025 15:36:21 +0000</pubDate>
    </item>
    <item>
      <title>Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students</title>
      <link>http://arxiv.org/abs/2512.21246v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Gaia Ebli, Bianca Raimondi, Maurizio Gabbrielli&lt;/p&gt;&lt;p&gt;The increasing integration of AI tools in education has led prior research to explore their impact on learning processes. Nevertheless, most existing studies focus on higher education and conventional instructional contexts, leaving open questions about how key learning factors are related in AI-mediated learning environments and how these relationships may vary across different age groups. Addressing these gaps, our work investigates whether four critical learning factors, experience, clarity, comfort, and motivation, maintain coherent interrelationships in AI-augmented educational settings, &lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21246v1</guid>
      <pubDate>Wed, 24 Dec 2025 15:43:58 +0000</pubDate>
    </item>
    <item>
      <title>SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance</title>
      <link>http://arxiv.org/abs/2512.21280v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Divij Dudeja, Mayukha Pal&lt;/p&gt;&lt;p&gt;The user of Engineering Manuals (EM) finds it difficult to read EM s because they are long, have a dense format which includes written documents, step by step procedures, and standard parameter lists for engineering equipment. Off the shelf transformers, especially compact ones, treat this material as a flat stream of tokens. This approach leads to confident but incorrect numeric answers and forces the models to memorize separate facts inefficiently&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21280v1</guid>
      <pubDate>Wed, 24 Dec 2025 16:59:04 +0000</pubDate>
    </item>
    <item>
      <title>Model Merging via Multi-Teacher Knowledge Distillation</title>
      <link>http://arxiv.org/abs/2512.21288v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Seyed Arshan Dalili, Mehrdad Mahdavi&lt;/p&gt;&lt;p&gt;Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21288v1</guid>
      <pubDate>Wed, 24 Dec 2025 17:10:44 +0000</pubDate>
    </item>
    <item>
      <title>Does the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks</title>
      <link>http://arxiv.org/abs/2512.21315v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Roy Turgeman, Tom Tirer&lt;/p&gt;&lt;p&gt;The data processing inequality is an information-theoretic principle stating that the information content of a signal cannot be increased by processing the observations. In particular, it suggests that there is no benefit in enhancing the signal or encoding it before addressing a classification problem. This assertion can be proven to be true for the case of the optimal Bayes classifier&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21315v1</guid>
      <pubDate>Wed, 24 Dec 2025 18:21:01 +0000</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks</title>
      <link>http://arxiv.org/abs/2512.21316v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ali Merali&lt;/p&gt;&lt;p&gt;This paper derives `Scaling Laws for Economic Impacts' -- empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 LLMs. We find that each year of AI model progress reduced task time by 8%, with 56% of gains driven by increased compute and 44% by algorithmic progress&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21316v1</guid>
      <pubDate>Wed, 24 Dec 2025 18:24:29 +0000</pubDate>
    </item>
    <item>
      <title>Measuring all the noises of LLM Evals</title>
      <link>http://arxiv.org/abs/2512.21326v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sida Wang&lt;/p&gt;&lt;p&gt;Separating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21326v1</guid>
      <pubDate>Wed, 24 Dec 2025 18:54:37 +0000</pubDate>
    </item>
    <item>
      <title>C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling</title>
      <link>http://arxiv.org/abs/2512.21332v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang&lt;/p&gt;&lt;p&gt;We present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing the LLM's causal representations acquired during pretraining, while also 2) being able to aggregate information from all tokens in the sequence, breaking the information bottleneck in EOS-based sequence embeddings, and 3) supporting flexible adaptation of embedding dimension, serving as an alternat&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21332v1</guid>
      <pubDate>Wed, 24 Dec 2025 18:59:01 +0000</pubDate>
    </item>
    <item>
      <title>Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty</title>
      <link>http://arxiv.org/abs/2512.21336v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin&lt;/p&gt;&lt;p&gt;Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.21336v1</guid>
      <pubDate>Wed, 24 Dec 2025 18:59:51 +0000</pubDate>
    </item>
  </channel>
</rss>
