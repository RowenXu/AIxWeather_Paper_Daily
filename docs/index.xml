<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 27 Jan 2026 03:49:16 +0000</lastBuildDate>
    <item>
      <title>From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic</title>
      <link>http://arxiv.org/abs/2601.18702v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hansheng Ren&lt;/p&gt;&lt;p&gt;Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18702v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:24:34 +0000</pubDate>
    </item>
    <item>
      <title>SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model</title>
      <link>http://arxiv.org/abs/2601.18707v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jan Hagnberger, Mathias Niepert&lt;/p&gt;&lt;p&gt;Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18707v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:34:16 +0000</pubDate>
    </item>
    <item>
      <title>Point transformer for protein structural heterogeneity analysis using CryoEM</title>
      <link>http://arxiv.org/abs/2601.18713v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Muyuan Chen, Muchen Li, Renjie Liao&lt;/p&gt;&lt;p&gt;Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18713v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:38:52 +0000</pubDate>
    </item>
    <item>
      <title>Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning</title>
      <link>http://arxiv.org/abs/2601.18714v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Judith Vilella-Cantos, Mauro Martini, Marcello Chiaberge, Mónica Ballesta, David Valiente&lt;/p&gt;&lt;p&gt;Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18714v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:38:56 +0000</pubDate>
    </item>
    <item>
      <title>Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules</title>
      <link>http://arxiv.org/abs/2601.18716v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Naeyma N. Islam, Thomas R. Caulfield&lt;/p&gt;&lt;p&gt;Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18716v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:39:59 +0000</pubDate>
    </item>
    <item>
      <title>One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment</title>
      <link>http://arxiv.org/abs/2601.18731v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hongru Cai, Yongqi Li, Tiezheng Yu, Fengbin Zhu, Wenjie Wang, Fuli Feng, Wenjie Li&lt;/p&gt;&lt;p&gt;Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18731v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:55:52 +0000</pubDate>
    </item>
    <item>
      <title>Optimal Use of Preferences in Artificial Intelligence Algorithms</title>
      <link>http://arxiv.org/abs/2601.18732v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Joshua S. Gans&lt;/p&gt;&lt;p&gt;Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18732v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:55:56 +0000</pubDate>
    </item>
    <item>
      <title>Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge</title>
      <link>http://arxiv.org/abs/2601.18733v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Li Kang, Heng Zhou, Xiufeng Song, Rui Li, Bruno N. Y. Chen, Ziye Wang, Ximeng Meng, Stone Tao&lt;/p&gt;&lt;p&gt;Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18733v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:56:19 +0000</pubDate>
    </item>
    <item>
      <title>Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems</title>
      <link>http://arxiv.org/abs/2601.18735v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jusheng Zhang, Yijia Fan, Kaitong Cai, Jing Yang, Jiawei Yao, Jian Wang, Guanlong Qu, Ziliang Chen&lt;/p&gt;&lt;p&gt;Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18735v1</guid>
      <pubDate>Mon, 26 Jan 2026 17:58:53 +0000</pubDate>
    </item>
    <item>
      <title>SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification</title>
      <link>http://arxiv.org/abs/2601.18739v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ignacio Antequera-Sánchez, Juan Luis Suárez-Díaz, Rosana Montes, Francisco Herrera&lt;/p&gt;&lt;p&gt;Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18739v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:01:46 +0000</pubDate>
    </item>
    <item>
      <title>TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models</title>
      <link>http://arxiv.org/abs/2601.18744v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Fangxu Yu, Xingang Guo, Lingzhi Yuan, Haoqiang Kang, Hongyu Zhao, Lianhui Qin, Furong Huang, Bin Hu&lt;/p&gt;&lt;p&gt;Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18744v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:04:54 +0000</pubDate>
    </item>
    <item>
      <title>Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback</title>
      <link>http://arxiv.org/abs/2601.18751v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Seyed Amir Hosseini, Maryam Abdolali, Amirhosein Tavakkoli, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi&lt;/p&gt;&lt;p&gt;Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18751v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:21:48 +0000</pubDate>
    </item>
    <item>
      <title>HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs</title>
      <link>http://arxiv.org/abs/2601.18753v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xinyue Zeng, Junhong Lin, Yujun Yan, Feng Guo, Liang Shi, Jun Wu, Dawei Zhou&lt;/p&gt;&lt;p&gt;The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18753v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:23:09 +0000</pubDate>
    </item>
    <item>
      <title>$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks</title>
      <link>http://arxiv.org/abs/2601.18754v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah&lt;/p&gt;&lt;p&gt;Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.   We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-b&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18754v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:25:07 +0000</pubDate>
    </item>
    <item>
      <title>Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory</title>
      <link>http://arxiv.org/abs/2601.18771v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yanming Liu, Xinyue Peng, Zixuan Yan, Yanxin Shen, Wenjie Xu, Yuefeng Huang, Xinyi Wang, Jiannan Cao&lt;/p&gt;&lt;p&gt;Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reaso&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18771v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:42:33 +0000</pubDate>
    </item>
    <item>
      <title>PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation</title>
      <link>http://arxiv.org/abs/2601.18777v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Abhishek Divekar, Anirban Majumder&lt;/p&gt;&lt;p&gt;Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18777v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:46:49 +0000</pubDate>
    </item>
    <item>
      <title>POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration</title>
      <link>http://arxiv.org/abs/2601.18779v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuxiao Qu, Amrith Setlur, Virginia Smith, Ruslan Salakhutdinov, Aviral Kumar&lt;/p&gt;&lt;p&gt;Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without impro&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18779v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:47:21 +0000</pubDate>
    </item>
    <item>
      <title>Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System</title>
      <link>http://arxiv.org/abs/2601.18785v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tiffany Wang, Yuqian Sun, Yi Wang, Melissa Roemmele, John Joon Young Chung, Max Kreminski&lt;/p&gt;&lt;p&gt;The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18785v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:51:20 +0000</pubDate>
    </item>
    <item>
      <title>Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes</title>
      <link>http://arxiv.org/abs/2601.18795v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Amrith Setlur, Zijian Wang, Andrew Cohen, Paria Rashidinejad, Sang Michael Xie&lt;/p&gt;&lt;p&gt;Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18795v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:57:00 +0000</pubDate>
    </item>
    <item>
      <title>ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models</title>
      <link>http://arxiv.org/abs/2601.18796v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Brian Ondov, Chia-Hsuan Chang, Yujia Zhou, Mauro Giuffrè, Hua Xu&lt;/p&gt;&lt;p&gt;Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.18796v1</guid>
      <pubDate>Mon, 26 Jan 2026 18:58:46 +0000</pubDate>
    </item>
  </channel>
</rss>
