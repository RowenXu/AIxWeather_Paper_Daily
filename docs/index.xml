<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 01 Jan 2026 03:51:50 +0000</lastBuildDate>
    <item>
      <title>Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach</title>
      <link>http://arxiv.org/abs/2512.24927v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuchen Jiao, Na Li, Changxiao Cai, Gen Li&lt;/p&gt;&lt;p&gt;Higher-order ODE solvers have become a standard tool for accelerating diffusion probabilistic model (DPM) sampling, motivating the widespread view that first-order methods are inherently slower and that increasing discretization order is the primary path to faster generation. This paper challenges this belief and revisits acceleration from a complementary angle: beyond solver order, the placement of DPM evaluations along the reverse-time dynamics can substantially affect sampling accuracy in the low-neural function evaluation (NFE) regime.   We propose a novel training-free, first-order sample&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24927v1</guid>
      <pubDate>Wed, 31 Dec 2025 15:35:53 +0000</pubDate>
    </item>
    <item>
      <title>Iterative Deployment Improves Planning Skills in LLMs</title>
      <link>http://arxiv.org/abs/2512.24940v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Augusto B. Corrêa, Yoav Gelberg, Luckeciano C. Melo, Ilia Shumailov, André G. Pereira, Yarin Gal&lt;/p&gt;&lt;p&gt;We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24940v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:03:14 +0000</pubDate>
    </item>
    <item>
      <title>RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment</title>
      <link>http://arxiv.org/abs/2512.24943v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chenji Lu, Zhuo Chen, Hui Zhao, Zhenyi Wang, Pengjie Wang, Jian Xu, Bo Zheng&lt;/p&gt;&lt;p&gt;Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24943v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:09:08 +0000</pubDate>
    </item>
    <item>
      <title>HaineiFRDM: Explore Diffusion to Restore Defects in Fast-Movement Films</title>
      <link>http://arxiv.org/abs/2512.24946v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rongji Xun, Junjie Yuan, Zhongjie Wang&lt;/p&gt;&lt;p&gt;Existing open-source film restoration methods show limited performance compared to commercial methods due to training with low-quality synthetic data and employing noisy optical flows. In addition, high-resolution films have not been explored by the open-source methods.We propose HaineiFRDM(Film Restoration Diffusion Model), a film restoration framework, to explore diffusion model's powerful content-understanding ability to help human expert better restore indistinguishable film defects.Specifically, we employ a patch-wise training and testing strategy to make restoring high-resolution films o&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24946v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:18:07 +0000</pubDate>
    </item>
    <item>
      <title>MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control</title>
      <link>http://arxiv.org/abs/2512.24955v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yongwei Zhang, Yuanzhe Xing, Quan Quan, Zhikun She&lt;/p&gt;&lt;p&gt;Achieving provable stability in model-free reinforcement learning (RL) remains a challenge, particularly in balancing exploration with rigorous safety. This article introduces MSACL, a framework that integrates exponential stability theory with maximum entropy RL through multi-step Lyapunov certificate learning. Unlike methods relying on complex reward engineering, MSACL utilizes off-policy multi-step data to learn Lyapunov certificates satisfying theoretical stability conditions&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24955v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:36:44 +0000</pubDate>
    </item>
    <item>
      <title>AMAP Agentic Planning Technical Report</title>
      <link>http://arxiv.org/abs/2512.24957v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yulan Hu, Xiangwen Zhang, Sheng Ouyang, Hao Yi, Lu Xu, Qinglin Lang, Lide Tan, Xiang Cheng&lt;/p&gt;&lt;p&gt;We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24957v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:39:09 +0000</pubDate>
    </item>
    <item>
      <title>Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning</title>
      <link>http://arxiv.org/abs/2512.24959v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; András Antos, András Millinghoffer, Péter Antal&lt;/p&gt;&lt;p&gt;Many modern AI and ML problems require evaluating partners' contributions through shared yet asymmetric, computationally intensive processes and the simultaneous selection of the most beneficial candidates. Sequential approaches to these problems can be unified under a new framework, Sequential Support Network Learning (SSNL), in which the goal is to select the most beneficial candidate set of partners for all participants using trials; that is, to learn a directed graph that represents the highest-performing contributions. We demonstrate that a new pure-exploration model, the semi-overlapping&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24959v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:42:00 +0000</pubDate>
    </item>
    <item>
      <title>ShowUI-$π$: Flow-based Generative Models as GUI Dexterous Hands</title>
      <link>http://arxiv.org/abs/2512.24965v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Siyuan Hu, Kevin Qinghong Lin, Mike Zheng Shou&lt;/p&gt;&lt;p&gt;Building intelligent agents capable of dexterous manipulation is essential for achieving human-like automation in both robotics and digital environments. However, existing GUI agents rely on discrete click predictions (x,y), which prohibits free-form, closed-loop trajectories (e.g. dragging a progress bar) that require continuous, on-the-fly perception and adjustment&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24965v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:51:14 +0000</pubDate>
    </item>
    <item>
      <title>The Impact of LLMs on Online News Consumption and Production</title>
      <link>http://arxiv.org/abs/2512.24968v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hangcheng Zhao, Ron Berman&lt;/p&gt;&lt;p&gt;Large language models (LLMs) change how consumers acquire information online; their bots also crawl news publishers' websites for training data and to answer consumer queries; and they provide tools that can lower the cost of content creation. These changes lead to predictions of adverse impact on news publishers in the form of lowered consumer demand, reduced demand for newsroom employees, and an increase in news "slop." Consequently, some publishers strategically responded by blocking LLM access to their websites using the robots.txt file standard.   Using high-frequency granular data, we do&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24968v1</guid>
      <pubDate>Wed, 31 Dec 2025 16:54:29 +0000</pubDate>
    </item>
    <item>
      <title>Evaluating the Impact of Compression Techniques on the Robustness of CNNs under Natural Corruptions</title>
      <link>http://arxiv.org/abs/2512.24971v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Itallo Patrick Castro Alves Da Silva, Emanuel Adler Medeiros Pereira, Erick de Andrade Barboza, Baldoino Fonseca dos Santos Neto, Marcio de Medeiros Ribeiro&lt;/p&gt;&lt;p&gt;Compressed deep learning models are crucial for deploying computer vision systems on resource-constrained devices. However, model compression may affect robustness, especially under natural corruption. Therefore, it is important to consider robustness evaluation while validating computer vision systems&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24971v1</guid>
      <pubDate>Wed, 31 Dec 2025 17:00:01 +0000</pubDate>
    </item>
    <item>
      <title>A Modal Logic for Possibilistic Reasoning with Fuzzy Formal Contexts</title>
      <link>http://arxiv.org/abs/2512.24980v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Prosenjit Howlader, Churn-Jung Liau&lt;/p&gt;&lt;p&gt;We introduce a two-sort weighted modal logic for possibilistic reasoning with fuzzy formal contexts. The syntax of the logic includes two types of weighted modal operators corresponding to classical necessity ($\Box$) and sufficiency ($\boxminus$) modalities and its formulas are interpreted in fuzzy formal contexts based on possibility theory. We present its axiomatization that is \emph{sound} with respect to the class of all fuzzy context models&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24980v1</guid>
      <pubDate>Wed, 31 Dec 2025 17:27:36 +0000</pubDate>
    </item>
    <item>
      <title>DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments</title>
      <link>http://arxiv.org/abs/2512.24985v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yohan Park, Hyunwoo Ha, Wonjun Jo, Tae-Hyun Oh&lt;/p&gt;&lt;p&gt;Vision Language Models (VLMs) are increasingly adopted as central reasoning modules for embodied agents. Existing benchmarks evaluate their capabilities under ideal, well-lit conditions, yet robust 24/7 operation demands performance under a wide range of visual degradations, including low-light conditions at night or in dark environments--a core necessity that has been largely overlooked. To address this underexplored challenge, we present DarkEQA, an open-source benchmark for evaluating EQA-relevant perceptual primitives under multi-level low-light conditions&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24985v1</guid>
      <pubDate>Wed, 31 Dec 2025 17:31:29 +0000</pubDate>
    </item>
    <item>
      <title>Classifying long legal documents using short random chunks</title>
      <link>http://arxiv.org/abs/2512.24997v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Luis Adrián Cabrera-Diego&lt;/p&gt;&lt;p&gt;Classifying legal documents is a challenge, besides their specialized vocabulary, sometimes they can be very long. This means that feeding full documents to a Transformers-based models for classification might be impossible, expensive or slow. Thus, we present a legal document classifier based on DeBERTa V3 and a LSTM, that uses as input a collection of 48 randomly-selected short chunks (max 128 tokens)&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24997v1</guid>
      <pubDate>Wed, 31 Dec 2025 17:48:08 +0000</pubDate>
    </item>
    <item>
      <title>Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis</title>
      <link>http://arxiv.org/abs/2512.24999v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Seunghoon Paik, Kangjie Zhou, Matus Telgarsky, Ryan J. Tibshirani&lt;/p&gt;&lt;p&gt;We introduce \textit{basic inequalities} for first-order iterative optimization algorithms, forming a simple and versatile framework that connects implicit and explicit regularization. While related inequalities appear in the literature, we isolate and highlight a specific form and develop it as a well-rounded tool for statistical analysis. Let $f$ denote the objective function to be optimized&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.24999v1</guid>
      <pubDate>Wed, 31 Dec 2025 17:49:37 +0000</pubDate>
    </item>
    <item>
      <title>Modeling Language as a Sequence of Thoughts</title>
      <link>http://arxiv.org/abs/2512.25026v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Nasim Borazjanizadeh, James McClelland&lt;/p&gt;&lt;p&gt;Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens. Yet, by relying primarily on surface-level co-occurrence statistics, they fail to form globally consistent latent representations of entities and events, lack of which contributes to brittleness in relational direction (e.g., reversal curse), contextualization errors, and data inefficiency. On the other hand, cognitive science shows that human comprehension involves converting the input linguistic stream into compact, event-like representations that persist in memory while verbatim fo&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.25026v1</guid>
      <pubDate>Wed, 31 Dec 2025 18:24:57 +0000</pubDate>
    </item>
    <item>
      <title>Generative Classifiers Avoid Shortcut Solutions</title>
      <link>http://arxiv.org/abs/2512.25034v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alexander C. Li, Ananya Kumar, Deepak Pathak&lt;/p&gt;&lt;p&gt;Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.25034v1</guid>
      <pubDate>Wed, 31 Dec 2025 18:31:46 +0000</pubDate>
    </item>
    <item>
      <title>Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings</title>
      <link>http://arxiv.org/abs/2512.25055v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tianzhi He, Farrokh Jazizadeh&lt;/p&gt;&lt;p&gt;This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytic&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.25055v1</guid>
      <pubDate>Wed, 31 Dec 2025 18:51:19 +0000</pubDate>
    </item>
    <item>
      <title>Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search</title>
      <link>http://arxiv.org/abs/2512.25065v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rohit Dwivedula, Divyanshu Saxena, Sujay Yadalam, Daehyeok Kim, Aditya Akella&lt;/p&gt;&lt;p&gt;Resource-management tasks in modern operating and distributed systems continue to rely primarily on hand-designed heuristics for tasks such as scheduling, caching, or active queue management. Designing performant heuristics is an expensive, time-consuming process that we are forced to continuously go through due to the constant flux of hardware, workloads and environments.   We propose a new alternative: synthesizing instance-optimal heuristics -- specialized for the exact workloads and hardware where they will be deployed -- using code-generating large language models (LLMs)&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.25065v1</guid>
      <pubDate>Wed, 31 Dec 2025 18:58:19 +0000</pubDate>
    </item>
    <item>
      <title>Coordinated Humanoid Manipulation with Choice Policies</title>
      <link>http://arxiv.org/abs/2512.25072v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Haozhi Qi, Yen-Jen Wang, Toru Lin, Brent Yi, Yi Ma, Koushil Sreenath, Jitendra Malik&lt;/p&gt;&lt;p&gt;Humanoid robots hold great promise for operating in human-centric environments, yet achieving robust whole-body coordination across the head, hands, and legs remains a major challenge. We present a system that combines a modular teleoperation interface with a scalable learning framework to address this problem. Our teleoperation design decomposes humanoid control into intuitive submodules, which include hand-eye coordination, grasp primitives, arm end-effector tracking, and locomotion&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.25072v1</guid>
      <pubDate>Wed, 31 Dec 2025 18:59:53 +0000</pubDate>
    </item>
    <item>
      <title>SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time</title>
      <link>http://arxiv.org/abs/2512.25075v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhening Huang, Hyeonho Jeong, Xuelin Chen, Yulia Gryaditskaya, Tuanfeng Y. Wang, Joan Lasenby, Chun-Hao Huang&lt;/p&gt;&lt;p&gt;We present SpaceTimePilot, a video diffusion model that disentangles space and time for controllable generative rendering. Given a monocular video, SpaceTimePilot can independently alter the camera viewpoint and the motion sequence within the generative process, re-rendering the scene for continuous and arbitrary exploration across space and time. To achieve this, we introduce an effective animation time-embedding mechanism in the diffusion process, allowing explicit control of the output video's motion sequence with respect to that of the source video&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.25075v1</guid>
      <pubDate>Wed, 31 Dec 2025 18:59:57 +0000</pubDate>
    </item>
  </channel>
</rss>
