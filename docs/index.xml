<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 17 Dec 2025 03:21:13 +0000</lastBuildDate>
    <item>
      <title>VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models</title>
      <link>http://arxiv.org/abs/2512.14554v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Nguyen Tien Dong, Minh-Anh Nguyen, Thanh Dat Hoang, Nguyen Tuan Ngoc, Dao Xuan Quang Minh, Phan Phi Hai, Nguyen Thi Ngoc Anh, Dang Van Tu&lt;/p&gt;&lt;p&gt;The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14554v1</guid>
      <pubDate>Tue, 16 Dec 2025 16:28:32 +0000</pubDate>
    </item>
    <item>
      <title>CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer</title>
      <link>http://arxiv.org/abs/2512.14560v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xianwei Cao, Dou Quan, Shuang Wang, Ning Huyan, Wei Wang, Yunan Li, Licheng Jiao&lt;/p&gt;&lt;p&gt;Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14560v1</guid>
      <pubDate>Tue, 16 Dec 2025 16:31:41 +0000</pubDate>
    </item>
    <item>
      <title>Polypersona: Persona-Grounded LLM for Synthetic Survey Responses</title>
      <link>http://arxiv.org/abs/2512.14562v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tejaswani Dash, Dinesh Karri, Anudeep Vurity, Gautam Datla, Tazeem Ahmad, Saima Rafi, Rohith Tangudu&lt;/p&gt;&lt;p&gt;This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14562v1</guid>
      <pubDate>Tue, 16 Dec 2025 16:33:23 +0000</pubDate>
    </item>
    <item>
      <title>Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection</title>
      <link>http://arxiv.org/abs/2512.14563v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tejaswani Dash, Gautam Datla, Anudeep Vurity, Tazeem Ahmad, Mohd Adnan, Saima Rafi, Saisha Patro, Saina Patro&lt;/p&gt;&lt;p&gt;Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14563v1</guid>
      <pubDate>Tue, 16 Dec 2025 16:33:59 +0000</pubDate>
    </item>
    <item>
      <title>Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies</title>
      <link>http://arxiv.org/abs/2512.14576v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ekaterina Artemova, Laurie Burchell, Daryna Dementieva, Shu Okabe, Mariya Shmatova, Pedro Ortiz Suarez&lt;/p&gt;&lt;p&gt;This tutorial (https://tum-nlp.github.io/low-resource-tutorial) is designed for NLP practitioners, researchers, and developers working with multilingual and low-resource languages who seek to create more equitable and socially impactful language technologies. Participants will walk away with a practical toolkit for building end-to-end NLP pipelines for underrepresented languages -- from data collection and web crawling to parallel sentence mining, machine translation, and downstream applications such as text classification and multimodal reasoning. The tutorial presents strategies for tackling&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14576v1</guid>
      <pubDate>Tue, 16 Dec 2025 16:44:17 +0000</pubDate>
    </item>
    <item>
      <title>Towards Nepali-language LLMs: Efficient GPT training with a Nepali BPE tokenizer</title>
      <link>http://arxiv.org/abs/2512.14585v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Adarsha Shrestha, Basanta Pokharel, Binit Shrestha, Smriti Adhikari, Dinesh Gothe&lt;/p&gt;&lt;p&gt;Nepali, a low-resource language spoken by over 32 million people, continues to face challenges in natural language processing (NLP) due to its complex grammar, agglutinative morphology, and limited availability of high-quality corpora. Most efforts to date have centered on basic encoder architectures; they remain insufficient for Nepali-specific text generation. This study presents a GPT-2-based Nepali language model trained using several training strategies inspired by GPT-3, including optimized learning rate schedules, batch scaling, and architectural refinements&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14585v1</guid>
      <pubDate>Tue, 16 Dec 2025 16:53:11 +0000</pubDate>
    </item>
    <item>
      <title>FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos</title>
      <link>http://arxiv.org/abs/2512.14601v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhaolun Li, Jichang Li, Yinqi Cai, Junye Chen, Xiaonan Luo, Guanbin Li, Rushi Lan&lt;/p&gt;&lt;p&gt;In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14601v1</guid>
      <pubDate>Tue, 16 Dec 2025 17:11:45 +0000</pubDate>
    </item>
    <item>
      <title>LLmFPCA-detect: LLM-powered Multivariate Functional PCA for Anomaly Detection in Sparse Longitudinal Texts</title>
      <link>http://arxiv.org/abs/2512.14604v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Prasanjit Dubey, Aritra Guha, Zhengyi Zhou, Qiong Wu, Xiaoming Huo, Paromita Dubey&lt;/p&gt;&lt;p&gt;Sparse longitudinal (SL) textual data arises when individuals generate text repeatedly over time (e.g., customer reviews, occasional social media posts, electronic medical records across visits), but the frequency and timing of observations vary across individuals. These complex textual data sets have immense potential to inform future policy and targeted recommendations. However, because SL text data lack dedicated methods and are noisy, heterogeneous, and prone to anomalies, detecting and inferring key patterns is challenging&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14604v1</guid>
      <pubDate>Tue, 16 Dec 2025 17:14:10 +0000</pubDate>
    </item>
    <item>
      <title>Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes</title>
      <link>http://arxiv.org/abs/2512.14617v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alessandro Trapasso, Luca Iocchi, Fabio Patrizi&lt;/p&gt;&lt;p&gt;Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14617v1</guid>
      <pubDate>Tue, 16 Dec 2025 17:26:24 +0000</pubDate>
    </item>
    <item>
      <title>JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction</title>
      <link>http://arxiv.org/abs/2512.14620v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Atsuyuki Miyai, Shota Onohara, Jeonghun Baek, Kiyoharu Aizawa&lt;/p&gt;&lt;p&gt;This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14620v1</guid>
      <pubDate>Tue, 16 Dec 2025 17:33:00 +0000</pubDate>
    </item>
    <item>
      <title>Learning the score under shape constraints</title>
      <link>http://arxiv.org/abs/2512.14624v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rebecca M. Lewis, Oliver Y. Feng, Henry W. J. Reeve, Min Xu, Richard J. Samworth&lt;/p&gt;&lt;p&gt;Score estimation has recently emerged as a key modern statistical challenge, due to its pivotal role in generative modelling via diffusion models. Moreover, it is an essential ingredient in a new approach to linear regression via convex $M$-estimation, where the corresponding error densities are projected onto the log-concave class. Motivated by these applications, we study the minimax risk of score estimation with respect to squared $L^2(P_0)$-loss, where $P_0$ denotes an underlying log-concave distribution on $\mathbb{R}$&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14624v1</guid>
      <pubDate>Tue, 16 Dec 2025 17:39:54 +0000</pubDate>
    </item>
    <item>
      <title>MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation</title>
      <link>http://arxiv.org/abs/2512.14629v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yash Vishe, Eric Xue, Xunyi Jiang, Zachary Novack, Junda Wu, Julian McAuley, Xin Xu&lt;/p&gt;&lt;p&gt;Music editing plays a vital role in modern music production, with applications in film, broadcasting, and game development. Recent advances in music generation models have enabled diverse editing tasks such as timbre transfer, instrument substitution, and genre transformation. However, many existing works overlook the evaluation of their ability to preserve musical facets that should remain unchanged during editing a property we define as Music Context Preservation (MCP)&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14629v1</guid>
      <pubDate>Tue, 16 Dec 2025 17:44:56 +0000</pubDate>
    </item>
    <item>
      <title>A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images</title>
      <link>http://arxiv.org/abs/2512.14640v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rao Muhammad Umer, Daniel Sens, Jonathan Noll, Christian Matek, Lukas Wolfseher, Rainer Spang, Ralf Huss, Johannes Raffler&lt;/p&gt;&lt;p&gt;Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14640v1</guid>
      <pubDate>Tue, 16 Dec 2025 17:58:03 +0000</pubDate>
    </item>
    <item>
      <title>WaveSim: A Wavelet-based Multi-scale Similarity Metric for Weather and Climate Fields</title>
      <link>http://arxiv.org/abs/2512.14656v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Gabriele Accarino, Viviana Acquaviva, Sara Shamekh, Duncan Watson-Parris, David Lawrence&lt;/p&gt;&lt;p&gt;We introduce WaveSim, a multi-scale similarity metric for the evaluation of spatial fields in weather and climate applications. WaveSim exploits wavelet transforms to decompose input fields into scale-specific wavelet coefficients. The metric is built by multiplying three orthogonal components derived from these coefficients: Magnitude, which quantifies similarities in the energy distribution of the coefficients, i.e., the intensity of the field; Displacement, which captures spatial shift by comparing the centers of mass of normalized energy distributions; and Structure, which assesses pattern&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14656v1</guid>
      <pubDate>Tue, 16 Dec 2025 18:15:53 +0000</pubDate>
    </item>
    <item>
      <title>gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation</title>
      <link>http://arxiv.org/abs/2512.14658v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alban Puech, Matteo Mazzonelli, Celia Cintas, Tamara R. Govindasamy, Mangaliso Mngomezulu, Jonas Weiss, Matteo Baù, Anna Varbella&lt;/p&gt;&lt;p&gt;We introduce gridfm-datakit-v1, a Python library for generating realistic and diverse Power Flow (PF) and Optimal Power Flow (OPF) datasets for training Machine Learning (ML) solvers. Existing datasets and libraries face three main challenges: (1) lack of realistic stochastic load and topology perturbations, limiting scenario diversity; (2) PF datasets are restricted to OPF-feasible points, hindering generalization of ML solvers to cases that violate operating limits (e.g., branch overloads or voltage violations); and (3) OPF datasets use fixed generator cost functions, limiting generalization&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14658v1</guid>
      <pubDate>Tue, 16 Dec 2025 18:17:50 +0000</pubDate>
    </item>
    <item>
      <title>VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image</title>
      <link>http://arxiv.org/abs/2512.14677v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sicheng Xu, Guojun Chen, Jiaolong Yang, Yizhong Zhang, Yu Deng, Steve Lin, Baining Guo&lt;/p&gt;&lt;p&gt;We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14677v1</guid>
      <pubDate>Tue, 16 Dec 2025 18:44:00 +0000</pubDate>
    </item>
    <item>
      <title>Spoken DialogSum: An Emotion-Rich Conversational Dataset for Spoken Dialogue Summarization</title>
      <link>http://arxiv.org/abs/2512.14687v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yen-Ju Lu, Kunxiao Gao, Mingrui Liang, Helin Wang, Thomas Thebaud, Laureano Moro-Velazquez, Najim Dehak, Jesus Villalba&lt;/p&gt;&lt;p&gt;Recent audio language models can follow long conversations. However, research on emotion-aware or spoken dialogue summarization is constrained by the lack of data that links speech, summaries, and paralinguistic cues. We introduce Spoken DialogSum, the first corpus aligning raw conversational audio with factual summaries, emotion-rich summaries, and utterance-level labels for speaker age, gender, and emotion&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14687v1</guid>
      <pubDate>Tue, 16 Dec 2025 18:54:20 +0000</pubDate>
    </item>
    <item>
      <title>Native and Compact Structured Latents for 3D Generation</title>
      <link>http://arxiv.org/abs/2512.14692v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jianfeng Xiang, Xiaoxue Chen, Sicheng Xu, Ruicheng Wang, Zelong Lv, Yu Deng, Hongyuan Zhu, Yue Dong&lt;/p&gt;&lt;p&gt;Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14692v1</guid>
      <pubDate>Tue, 16 Dec 2025 18:58:28 +0000</pubDate>
    </item>
    <item>
      <title>Universal Reasoning Model</title>
      <link>http://arxiv.org/abs/2512.14693v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zitian Gao, Lynx Chen, Yihao Xiao, He Xing, Ran Tao, Haoming Luo, Joey Zhou, Bryan Dai&lt;/p&gt;&lt;p&gt;Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14693v1</guid>
      <pubDate>Tue, 16 Dec 2025 18:58:45 +0000</pubDate>
    </item>
    <item>
      <title>TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2512.14698v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jun Zhang, Teng Wang, Yuying Ge, Yixiao Ge, Xinhao Li, Ying Shan, Limin Wang&lt;/p&gt;&lt;p&gt;This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.14698v1</guid>
      <pubDate>Tue, 16 Dec 2025 18:59:58 +0000</pubDate>
    </item>
  </channel>
</rss>
