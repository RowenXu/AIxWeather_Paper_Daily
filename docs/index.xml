<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 23 Jan 2026 03:43:50 +0000</lastBuildDate>
    <item>
      <title>Designing faster mixed integer linear programming algorithm via learning the optimal path</title>
      <link>http://arxiv.org/abs/2601.16056v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ruizhi Liu, Liming Xu, Xulin Huang, Jingyan Sui, Shizhe Ding, Boyang Xia, Chungong Yu, Dongbo Bu&lt;/p&gt;&lt;p&gt;Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from &lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16056v1</guid>
      <pubDate>Thu, 22 Jan 2026 15:41:22 +0000</pubDate>
    </item>
    <item>
      <title>On damage of interpolation to adversarial robustness in regression</title>
      <link>http://arxiv.org/abs/2601.16070v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jingfu Peng, Yuhong Yang&lt;/p&gt;&lt;p&gt;Deep neural networks (DNNs) typically involve a large number of parameters and are trained to achieve zero or near-zero training error. Despite such interpolation, they often exhibit strong generalization performance on unseen data, a phenomenon that has motivated extensive theoretical investigations. Comforting results show that interpolation indeed may not affect the minimax rate of convergence under the squared error loss&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16070v1</guid>
      <pubDate>Thu, 22 Jan 2026 16:09:00 +0000</pubDate>
    </item>
    <item>
      <title>Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics</title>
      <link>http://arxiv.org/abs/2601.16087v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sukesh Subaharan&lt;/p&gt;&lt;p&gt;Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16087v1</guid>
      <pubDate>Thu, 22 Jan 2026 16:34:05 +0000</pubDate>
    </item>
    <item>
      <title>Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</title>
      <link>http://arxiv.org/abs/2601.16091v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Saar Cohen&lt;/p&gt;&lt;p&gt;Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should be assigned to clusters, but assignments need not be immediate. Specifically, upon arrival, each point's location is revealed, and an online algorithm has to irrevocably assign it to an existing cluste&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16091v1</guid>
      <pubDate>Thu, 22 Jan 2026 16:42:05 +0000</pubDate>
    </item>
    <item>
      <title>Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources</title>
      <link>http://arxiv.org/abs/2601.16108v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Marzieh Adeli Shamsabad, Hamed Ghodrati&lt;/p&gt;&lt;p&gt;Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16108v1</guid>
      <pubDate>Thu, 22 Jan 2026 16:55:48 +0000</pubDate>
    </item>
    <item>
      <title>Synthetic Augmentation in Imbalanced Learning: When It Helps, When It Hurts, and How Much to Add</title>
      <link>http://arxiv.org/abs/2601.16120v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhengchi Ma, Anru R. Zhang&lt;/p&gt;&lt;p&gt;Imbalanced classification, where one class is observed far less frequently than the other, often causes standard training procedures to prioritize the majority class and perform poorly on rare but important cases. A classic and widely used remedy is to augment the minority class with synthetic examples, but two basic questions remain under-resolved: when does synthetic augmentation actually help, and how many synthetic samples should be generated?   We develop a unified statistical framework for synthetic augmentation in imbalanced learning, studying models trained on imbalanced data augmented&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16120v1</guid>
      <pubDate>Thu, 22 Jan 2026 17:15:26 +0000</pubDate>
    </item>
    <item>
      <title>Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging</title>
      <link>http://arxiv.org/abs/2601.16127v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart&lt;/p&gt;&lt;p&gt;Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16127v1</guid>
      <pubDate>Thu, 22 Jan 2026 17:28:24 +0000</pubDate>
    </item>
    <item>
      <title>Replicating Human Motivated Reasoning Studies with LLMs</title>
      <link>http://arxiv.org/abs/2601.16130v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Neeley Pate, Adiba Mahbub Proma, Hangfeng He, James N. Druckman, Daniel Molden, Gourab Ghoshal, Ehsan Hoque&lt;/p&gt;&lt;p&gt;Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expected human behavior&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16130v1</guid>
      <pubDate>Thu, 22 Jan 2026 17:29:07 +0000</pubDate>
    </item>
    <item>
      <title>LLM Prompt Evaluation for Educational Applications</title>
      <link>http://arxiv.org/abs/2601.16134v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Langdon Holmes, Adam Coscia, Scott Crossley, Joon Suh Choi, Wesley Morris&lt;/p&gt;&lt;p&gt;As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for evaluating prompts, demonstrated through an analysis of LLM-generated follow-up questions in a structured dialogue activity. Six prompt templates were designed and tested&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16134v1</guid>
      <pubDate>Thu, 22 Jan 2026 17:31:25 +0000</pubDate>
    </item>
    <item>
      <title>Learning to Watermark in the Latent Space of Generative Models</title>
      <link>http://arxiv.org/abs/2601.16140v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sylvestre-Alvise Rebuffi, Tuan Tran, Valeriu Lacatusu, Pierre Fernandez, Tomáš Souček, Nikola Jovanović, Tom Sander, Hady Elsahar&lt;/p&gt;&lt;p&gt;Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16140v1</guid>
      <pubDate>Thu, 22 Jan 2026 17:34:30 +0000</pubDate>
    </item>
    <item>
      <title>Pay (Cross) Attention to the Melody: Curriculum Masking for Single-Encoder Melodic Harmonization</title>
      <link>http://arxiv.org/abs/2601.16150v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Maximos Kaliakatsos-Papakostas, Dimos Makris, Konstantinos Soiledis, Konstantinos-Theodoros Tsamis, Vassilis Katsouros, Emilios Cambouropoulos&lt;/p&gt;&lt;p&gt;Melodic harmonization, the task of generating harmonic accompaniments for a given melody, remains a central challenge in computational music generation. Recent single encoder transformer approaches have framed harmonization as a masked sequence modeling problem, but existing training curricula inspired by discrete diffusion often result in weak (cross) attention between melody and harmony. This leads to limited exploitation of melodic cues, particularly in out-of-domain contexts&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16150v1</guid>
      <pubDate>Thu, 22 Jan 2026 17:46:31 +0000</pubDate>
    </item>
    <item>
      <title>Substrate Stability Under Persistent Disagreement: Structural Constraints for Neutral Ontological Substrates</title>
      <link>http://arxiv.org/abs/2601.16152v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Denise M. Case&lt;/p&gt;&lt;p&gt;Modern data systems increasingly operate under conditions of persistent legal, political, and analytic disagreement. In such settings, interoperability cannot rely on shared interpretation, negotiated semantics, or centralized authority. Instead, representations must function as neutral substrates that preserve stable reference across incompatible extensions&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16152v1</guid>
      <pubDate>Thu, 22 Jan 2026 17:51:02 +0000</pubDate>
    </item>
    <item>
      <title>Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning</title>
      <link>http://arxiv.org/abs/2601.16163v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Moo Jin Kim, Yihuai Gao, Tsung-Yi Lin, Yen-Chen Lin, Yunhao Ge, Grace Lam, Percy Liang, Shuran Song&lt;/p&gt;&lt;p&gt;Recent video generation models demonstrate remarkable ability to capture complex physical interactions and scene evolution over time. To leverage their spatiotemporal priors, robotics works have adapted video models for policy learning but introduce complexity by requiring multiple stages of post-training and new architectural components for action generation. In this work, we introduce Cosmos Policy, a simple approach for adapting a large pretrained video model (Cosmos-Predict2) into an effective robot policy through a single stage of post-training on the robot demonstration data collected on&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16163v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:09:30 +0000</pubDate>
    </item>
    <item>
      <title>Structured Hints for Sample-Efficient Lean Theorem Proving</title>
      <link>http://arxiv.org/abs/2601.16172v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zachary Burton&lt;/p&gt;&lt;p&gt;State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maxi&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16172v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:16:46 +0000</pubDate>
    </item>
    <item>
      <title>Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints</title>
      <link>http://arxiv.org/abs/2601.16174v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yiyao Yang&lt;/p&gt;&lt;p&gt;Uncertainty estimation in machine learning has traditionally focused on the prediction stage, aiming to quantify confidence in model outputs while treating learned representations as deterministic and reliable by default. In this work, we challenge this implicit assumption and argue that reliability should be regarded as a first-class property of learned representations themselves. We propose a principled framework for reliable representation learning that explicitly models representation-level uncertainty and leverages structural constraints as inductive biases to regularize the space of feas&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16174v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:19:52 +0000</pubDate>
    </item>
    <item>
      <title>Learning to Discover at Test Time</title>
      <link>http://arxiv.org/abs/2601.16175v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mert Yuksekgonul, Daniel Koceja, Xinhao Li, Federico Bianchi, Jed McCaleb, Xiaolong Wang, Jan Kautz, Yejin Choi&lt;/p&gt;&lt;p&gt;How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16175v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:24:00 +0000</pubDate>
    </item>
    <item>
      <title>Pushing the limits of unconstrained machine-learned interatomic potentials</title>
      <link>http://arxiv.org/abs/2601.16195v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Filippo Bigi, Paolo Pegolo, Arslan Mazitov, Michele Ceriotti&lt;/p&gt;&lt;p&gt;Machine-learned interatomic potentials (MLIPs) are increasingly used to replace computationally demanding electronic-structure calculations to model matter at the atomic scale. The most commonly used model architectures are constrained to fulfill a number of physical laws exactly, from geometric symmetries to energy conservation. Evidence is mounting that relaxing some of these constraints can be beneficial to the efficiency and (somewhat surprisingly) accuracy of MLIPs, even though care should be taken to avoid qualitative failures associated with the breaking of physical symmetries&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16195v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:46:58 +0000</pubDate>
    </item>
    <item>
      <title>Counterfactual Training: Teaching Models Plausible and Actionable Explanations</title>
      <link>http://arxiv.org/abs/2601.16205v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Patrick Altmeyer, Aleksander Buszydlik, Arie van Deursen, Cynthia C. S. Liem&lt;/p&gt;&lt;p&gt;We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16205v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:56:14 +0000</pubDate>
    </item>
    <item>
      <title>LLM-in-Sandbox Elicits General Agentic Intelligence</title>
      <link>http://arxiv.org/abs/2601.16206v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Daixuan Cheng, Shaohan Huang, Yuxian Gu, Huatong Song, Guoxin Chen, Li Dong, Wayne Xin Zhao, Ji-Rong Wen&lt;/p&gt;&lt;p&gt;We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16206v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:57:09 +0000</pubDate>
    </item>
    <item>
      <title>Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition</title>
      <link>http://arxiv.org/abs/2601.16211v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Geo Ahn, Inwoong Lee, Taeoh Kim, Minho Shim, Dongyoon Wee, Jinwoo Choi&lt;/p&gt;&lt;p&gt;We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2601.16211v1</guid>
      <pubDate>Thu, 22 Jan 2026 18:59:13 +0000</pubDate>
    </item>
  </channel>
</rss>
