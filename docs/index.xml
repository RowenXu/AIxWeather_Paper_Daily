<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 14 Feb 2026 04:11:09 +0000</lastBuildDate>
    <item>
      <title>SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization</title>
      <link>http://arxiv.org/abs/2602.12187v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sunghwan Kim, Wooseok Jeong, Serin Kim, Sangam Lee, Dongha Lee&lt;/p&gt;&lt;p&gt;Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 摘要未提供更多细节，建议阅读原文。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12187v1</guid>
      <pubDate>Thu, 12 Feb 2026 17:18:00 +0000</pubDate>
    </item>
    <item>
      <title>Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education</title>
      <link>http://arxiv.org/abs/2602.12196v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mohamed Huti, Alasdair Mackintosh, Amy Waldock, Dominic Andrews, Maxime Lelièvre, Moritz Boos, Tobias Murray, Paul Atherton&lt;/p&gt;&lt;p&gt;AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as &lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12196v1</guid>
      <pubDate>Thu, 12 Feb 2026 17:29:03 +0000</pubDate>
    </item>
    <item>
      <title>DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing</title>
      <link>http://arxiv.org/abs/2602.12205v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dianyi Wang, Ruihang Li, Feng Han, Chaofan Ma, Wei Song, Siyuan Wang, Yibin Wang, Yi Xin&lt;/p&gt;&lt;p&gt;Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., &gt;10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12205v1</guid>
      <pubDate>Thu, 12 Feb 2026 17:44:24 +0000</pubDate>
    </item>
    <item>
      <title>VIRENA: Virtual Arena for Research, Education, and Democratic Innovation</title>
      <link>http://arxiv.org/abs/2602.12207v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Emma Hoes, K. Jonathan Klueser, Fabrizio Gilardi&lt;/p&gt;&lt;p&gt;Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12207v1</guid>
      <pubDate>Thu, 12 Feb 2026 17:46:52 +0000</pubDate>
    </item>
    <item>
      <title>The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics</title>
      <link>http://arxiv.org/abs/2602.12218v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Christian Internò, Jumpei Yamaguchi, Loren Amdahl-Culleton, Markus Olhofer, David Klindt, Barbara Hammer&lt;/p&gt;&lt;p&gt;Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12218v1</guid>
      <pubDate>Thu, 12 Feb 2026 17:56:07 +0000</pubDate>
    </item>
    <item>
      <title>Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training</title>
      <link>http://arxiv.org/abs/2602.12222v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Miaosen Zhang, Yishan Liu, Shuxia Lin, Xu Yang, Qi Dai, Chong Luo, Weihao Jiang, Peng Hou&lt;/p&gt;&lt;p&gt;Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12222v1</guid>
      <pubDate>Thu, 12 Feb 2026 17:59:58 +0000</pubDate>
    </item>
    <item>
      <title>Bandit Learning in Matching Markets with Interviews</title>
      <link>http://arxiv.org/abs/2602.12224v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Amirmahdi Mirfakhar, Xuchuang Wang, Mengfan Xu, Hedyeh Beyhaghi, Mohammad Hajiesmaili&lt;/p&gt;&lt;p&gt;Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \textit{low-cost hints} that reveal partial preference information to both sides&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12224v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:03:37 +0000</pubDate>
    </item>
    <item>
      <title>Olmix: A Framework for Data Mixing Throughout LM Development</title>
      <link>http://arxiv.org/abs/2602.12237v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mayee F. Chen, Tyler Murray, David Heineman, Matt Jordan, Hannaneh Hajishirzi, Christopher Ré, Luca Soldaini, Kyle Lo&lt;/p&gt;&lt;p&gt;Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addresses two such challenges&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12237v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:16:05 +0000</pubDate>
    </item>
    <item>
      <title>Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces</title>
      <link>http://arxiv.org/abs/2602.12245v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Anthony Kobanda, Waris Radji&lt;/p&gt;&lt;p&gt;Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed distance values (cost-to-go) that support reaching goals under asymmetric dynamics. In this short article, we connect these viewpoints by restricting attention to a principled class of JEPA energy functions : intrinsic (least-action) energies, defined as infima of accumulated local effort over admissib&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12245v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:30:27 +0000</pubDate>
    </item>
    <item>
      <title>ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction</title>
      <link>http://arxiv.org/abs/2602.12247v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Nick Ferguson, Josh Pennington, Narek Beghian, Aravind Mohan, Douwe Kiela, Sheshansh Agrawal, Thien Hang Nguyen&lt;/p&gt;&lt;p&gt;Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12247v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:31:37 +0000</pubDate>
    </item>
    <item>
      <title>"Sorry, I Didn't Catch That": How Speech Models Miss What Matters Most</title>
      <link>http://arxiv.org/abs/2602.12249v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kaitlyn Zhou, Martijn Bartelds, Federico Bianchi, James Zou&lt;/p&gt;&lt;p&gt;Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12249v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:36:09 +0000</pubDate>
    </item>
    <item>
      <title>A technical curriculum on language-oriented artificial intelligence in translation and specialised communication</title>
      <link>http://arxiv.org/abs/2602.12251v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ralph Krüger&lt;/p&gt;&lt;p&gt;This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&amp;T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12251v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:37:23 +0000</pubDate>
    </item>
    <item>
      <title>On the implicit regularization of Langevin dynamics with projected noise</title>
      <link>http://arxiv.org/abs/2602.12257v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Govind Menon, Austin J. Stromme, Adrien Vacher&lt;/p&gt;&lt;p&gt;We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12257v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:45:42 +0000</pubDate>
    </item>
    <item>
      <title>Think like a Scientist: Physics-guided LLM Agent for Equation Discovery</title>
      <link>http://arxiv.org/abs/2602.12259v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jianke Yang, Ohm Venkatachalam, Mohammad Kianezhad, Sharvaree Vadgama, Rose Yu&lt;/p&gt;&lt;p&gt;Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12259v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:49:27 +0000</pubDate>
    </item>
    <item>
      <title>CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use</title>
      <link>http://arxiv.org/abs/2602.12268v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhen Zhang, Kaiqiang Song, Xun Wang, Yebowen Hu, Weixiang Yan, Chenyang Zhao, Henry Peng Zou, Haoyun Deng&lt;/p&gt;&lt;p&gt;AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12268v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:55:09 +0000</pubDate>
    </item>
    <item>
      <title>Creative Ownership in the Age of AI</title>
      <link>http://arxiv.org/abs/2602.12270v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Annie Liang, Jay Lu&lt;/p&gt;&lt;p&gt;Copyright law focuses on whether a new work is "substantially similar" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12270v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:56:42 +0000</pubDate>
    </item>
    <item>
      <title>Agentic Test-Time Scaling for WebAgents</title>
      <link>http://arxiv.org/abs/2602.12276v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Nicholas Lee, Lutfi Eren Erdogan, Chris Joseph John, Surya Krishnapillai, Michael W. Mahoney, Kurt Keutzer, Amir Gholami&lt;/p&gt;&lt;p&gt;Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12276v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:58:30 +0000</pubDate>
    </item>
    <item>
      <title>AttentionRetriever: Attention Layers are Secretly Long Document Retrievers</title>
      <link>http://arxiv.org/abs/2602.12278v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; David Jiahao Fu, Lam Thanh Do, Jiayu Li, Kevin Chen-Chuan Chang&lt;/p&gt;&lt;p&gt;Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12278v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:59:35 +0000</pubDate>
    </item>
    <item>
      <title>UniT: Unified Multimodal Chain-of-Thought Test-time Scaling</title>
      <link>http://arxiv.org/abs/2602.12279v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Leon Liangyu Chen, Haoyu Ma, Zhipeng Fan, Ziqi Huang, Animesh Sinha, Xiaoliang Dai, Jialiang Wang, Zecheng He&lt;/p&gt;&lt;p&gt;Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extendin&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12279v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:59:49 +0000</pubDate>
    </item>
    <item>
      <title>Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment</title>
      <link>http://arxiv.org/abs/2602.12281v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jacky Kwok, Xilun Zhang, Mengdi Xu, Yuejiang Liu, Azalia Mirhoseini, Chelsea Finn, Marco Pavone&lt;/p&gt;&lt;p&gt;The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-ti&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2602.12281v1</guid>
      <pubDate>Thu, 12 Feb 2026 18:59:59 +0000</pubDate>
    </item>
  </channel>
</rss>
