<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>arXiv · 气象 × AI 精选论文</title>
    <link>https://example.github.io/arxiv-meteo-ai-rss/</link>
    <description>每日10:00自动更新 · 气象与AI交叉最新论文与要点</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 03 Dec 2025 03:20:10 +0000</lastBuildDate>
    <item>
      <title>Towards a fully differentiable digital twin for solar cells</title>
      <link>http://arxiv.org/abs/2512.02904v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Marie Louise Schubert, Houssam Metni, Jan David Fischbach, Benedikt Zerulla, Marjan Krstić, Ulrich W. Paetzold, Seyedamir Orooji, Olivier J. J. Ronsin&lt;/p&gt;&lt;p&gt;Maximizing energy yield (EY) - the total electric energy generated by a solar cell within a year at a specific location - is crucial in photovoltaics (PV), especially for emerging technologies. Computational methods provide the necessary insights and guidance for future research. However, existing simulations typically focus on only isolated aspects of solar cells&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02904v1</guid>
      <pubDate>Tue, 02 Dec 2025 16:20:58 +0000</pubDate>
    </item>
    <item>
      <title>MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding</title>
      <link>http://arxiv.org/abs/2512.02906v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Fan Yang, Kaihao Zhang&lt;/p&gt;&lt;p&gt;Understanding high-resolution images remains a significant challenge for multimodal large language models (MLLMs). Recent study address this issue by dividing the image into smaller crops and computing the semantic similarity between each crop and a query using a pretrained retrieval-augmented generation (RAG) model. The most relevant crops are then selected to localize the target object and suppress irrelevant information&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02906v1</guid>
      <pubDate>Tue, 02 Dec 2025 16:22:01 +0000</pubDate>
    </item>
    <item>
      <title>In Silico Development of Psychometric Scales: Feasibility of Representative Population Data Simulation with LLMs</title>
      <link>http://arxiv.org/abs/2512.02910v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Enrico Cipriani, Pavel Okopnyi, Danilo Menicucci, Simone Grassini&lt;/p&gt;&lt;p&gt;Developing and validating psychometric scales requires large samples, multiple testing phases, and substantial resources. Recent advances in Large Language Models (LLMs) enable the generation of synthetic participant data by prompting models to answer items while impersonating individuals of specific demographic profiles, potentially allowing in silico piloting before real data collection. Across four preregistered studies (N = circa 300 each), we tested whether LLM-simulated datasets can reproduce the latent structures and measurement properties of human responses&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02910v1</guid>
      <pubDate>Tue, 02 Dec 2025 16:26:17 +0000</pubDate>
    </item>
    <item>
      <title>Hypothesis Testing for Generalized Thurstone Models</title>
      <link>http://arxiv.org/abs/2512.02912v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Anuran Makur, Japneet Singh&lt;/p&gt;&lt;p&gt;In this work, we develop a hypothesis testing framework to determine whether pairwise comparison data is generated by an underlying \emph{generalized Thurstone model} $\mathcal{T}_F$ for a given choice function $F$. While prior work has predominantly focused on parameter estimation and uncertainty quantification for such models, we address the fundamental problem of minimax hypothesis testing for $\mathcal{T}_F$ models. We formulate this testing problem by introducing a notion of separation distance between general pairwise comparison models and the class of $\mathcal{T}_F$ models&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02912v1</guid>
      <pubDate>Tue, 02 Dec 2025 16:32:42 +0000</pubDate>
    </item>
    <item>
      <title>Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning</title>
      <link>http://arxiv.org/abs/2512.02914v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhonghao He, Tianyi Qiu, Hirokazu Shirado, Maarten Sap&lt;/p&gt;&lt;p&gt;Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrenchment and confirmation bias, rather than enhancing truth-seeking behavior. In this study, we propose a systematic evaluation framework for belief entrenchment in LLM reasoning by leveraging the Martingale property from Bayesian statistics&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02914v1</guid>
      <pubDate>Tue, 02 Dec 2025 16:34:05 +0000</pubDate>
    </item>
    <item>
      <title>Fast Gaussian Process Approximations for Autocorrelated Data</title>
      <link>http://arxiv.org/abs/2512.02925v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ahmadreza Chokhachian, Matthias Katzfuss, Yu Ding&lt;/p&gt;&lt;p&gt;This paper is concerned with the problem of how to speed up computation for Gaussian process models trained on autocorrelated data. The Gaussian process model is a powerful tool commonly used in nonlinear regression applications. Standard regression modeling assumes random samples and an independently, identically distributed noise&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02925v1</guid>
      <pubDate>Tue, 02 Dec 2025 16:46:07 +0000</pubDate>
    </item>
    <item>
      <title>Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench</title>
      <link>http://arxiv.org/abs/2512.02942v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Lanxiang Hu, Abhilash Shankarampeta, Yixin Huang, Zilin Dai, Haoyang Yu, Yujie Zhao, Haoqiang Kang, Daniel Zhao&lt;/p&gt;&lt;p&gt;The next frontier for video generation lies in developing models capable of zero-shot reasoning, where understanding real-world scientific laws is crucial for accurate physical outcome modeling under diverse conditions. However, existing video benchmarks are physical commonsense-based, offering limited insight into video models' scientific reasoning capability. We introduce VideoScience-Bench, a benchmark designed to evaluate undergraduate-level scientific understanding in video models&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02942v1</guid>
      <pubDate>Tue, 02 Dec 2025 17:11:23 +0000</pubDate>
    </item>
    <item>
      <title>Lumos: Let there be Language Model System Certification</title>
      <link>http://arxiv.org/abs/2512.02966v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Isha Chaudhary, Vedaant Jain, Avaljot Singh, Kavya Sachdeva, Sayan Ranu, Gagandeep Singh&lt;/p&gt;&lt;p&gt;We introduce the first principled framework, Lumos, for specifying and formally certifying Language Model System (LMS) behaviors. Lumos is an imperative probabilistic programming DSL over graphs, with constructs to generate independent and identically distributed prompts for LMS. It offers a structured view of prompt distributions via graphs, forming random prompts from sampled subgraphs&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02966v1</guid>
      <pubDate>Tue, 02 Dec 2025 17:44:47 +0000</pubDate>
    </item>
    <item>
      <title>Identification of Multivariate Measurement Error Models</title>
      <link>http://arxiv.org/abs/2512.02970v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yingyao Hu&lt;/p&gt;&lt;p&gt;This paper develops new identification results for multidimensional continuous measurement-error models where all observed measurements are contaminated by potentially correlated errors and none provides an injective mapping of the latent distribution. Using third order cross moments, the paper constructs a three way tensor whose unique decomposition, guaranteed by Kruskal theorem, identifies the factor loading matrices. Starting with a linear structure, the paper recovers the full distribution of latent factors by constructing suitable measurements and applying scalar or multivariate versions&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02970v1</guid>
      <pubDate>Tue, 02 Dec 2025 17:49:48 +0000</pubDate>
    </item>
    <item>
      <title>Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic</title>
      <link>http://arxiv.org/abs/2512.02987v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Muyu Pan, Dheeraj Kodakandla, Mahfuza Farooque&lt;/p&gt;&lt;p&gt;Recent advances in natural language processing (NLP), particularly large language models (LLMs), have motivated the automatic translation of natural language statements into formal logic without human intervention. This enables automated reasoning and facilitates debugging, finding loop invariants, and adhering to specifications in software systems. However, hallucinations-incorrect outputs generated by LLMs are challenging, particularly for logical translation tasks requiring precision&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.02987v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:03:06 +0000</pubDate>
    </item>
    <item>
      <title>Invasive Context Engineering to Control Large Language Models</title>
      <link>http://arxiv.org/abs/2512.03001v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Thomas Rivasseau&lt;/p&gt;&lt;p&gt;Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03001v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:25:55 +0000</pubDate>
    </item>
    <item>
      <title>From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?</title>
      <link>http://arxiv.org/abs/2512.03005v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dawei Li, Abdullah Alnaibari, Arslan Bisharat, Manny Sandoval, Deborah Hall, Yasin Silva, Huan Liu&lt;/p&gt;&lt;p&gt;The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03005v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:31:18 +0000</pubDate>
    </item>
    <item>
      <title>In-Context Sync-LoRA for Portrait Video Editing</title>
      <link>http://arxiv.org/abs/2512.03013v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sagi Polaczek, Or Patashnik, Ali Mahdavi-Amiri, Daniel Cohen-Or&lt;/p&gt;&lt;p&gt;Editing portrait videos is a challenging task that requires flexible yet precise control over a wide range of modifications, such as appearance changes, expression edits, or the addition of objects. The key difficulty lies in preserving the subject's original temporal behavior, demanding that every edited frame remains precisely synchronized with the corresponding source frame. We present Sync-LoRA, a method for editing portrait videos that achieves high-quality visual modifications while maintaining frame-accurate synchronization and identity consistency&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03013v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:40:35 +0000</pubDate>
    </item>
    <item>
      <title>Distribution-Calibrated Inference time compute for Thinking LLM-as-a-Judge</title>
      <link>http://arxiv.org/abs/2512.03019v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hamid Dadkhahi, Firas Trabelsi, Parker Riley, Juraj Juraska, Mehdi Mirzazadeh&lt;/p&gt;&lt;p&gt;Thinking Large Language Models (LLMs) used as judges for pairwise preferences remain noisy at the single-sample level, and common aggregation rules (majority vote, soft self-consistency, or instruction-based self-aggregation) are inconsistent when ties are allowed. We study inference-time compute (ITC) for evaluators that generate n independent thinking-rating samples per item, and propose a principled, distribution-calibrated aggregation scheme. Our method models three-way preferences with a Bradley-Terry-Davidson formulation on rating counts, leveraging both polarity (margin among non-ties) &lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03019v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:46:47 +0000</pubDate>
    </item>
    <item>
      <title>TokenPowerBench: Benchmarking the Power Consumption of LLM Inference</title>
      <link>http://arxiv.org/abs/2512.03024v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chenxu Niu, Wei Zhang, Jie Li, Yongjian Zhao, Tongyang Wang, Xi Wang, Yong Chen&lt;/p&gt;&lt;p&gt;Large language model (LLM) services now answer billions of queries per day, and industry reports show that inference, not training, accounts for more than 90% of total power consumption. However, existing benchmarks focus on either training/fine-tuning or performance of inference and provide little support for power consumption measurement and analysis of inference. We introduce TokenPowerBench, the first lightweight and extensible benchmark designed for LLM-inference power consumption studies&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;br/&gt;- 任务：降尺度/预报/临近预测等应用场景。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03024v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:50:17 +0000</pubDate>
    </item>
    <item>
      <title>LORE: A Large Generative Model for Search Relevance</title>
      <link>http://arxiv.org/abs/2512.03025v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chenji Lu, Zhuo Chen, Hui Zhao, Zhiyuan Zeng, Gang Zhao, Junjie Ren, Ruicong Xu, Haoran Li&lt;/p&gt;&lt;p&gt;Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\% improvement in online GoodRate metrics&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03025v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:50:42 +0000</pubDate>
    </item>
    <item>
      <title>The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models</title>
      <link>http://arxiv.org/abs/2512.03026v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Saeid Jamshidi, Kawser Wazed Nafi, Arghavan Moradi Dakhel, Negar Shahabi, Foutse Khomh&lt;/p&gt;&lt;p&gt;The rapid advancement and adaptability of Large Language Models (LLMs) highlight the need for moral consistency, the capacity to maintain ethically coherent reasoning across varied contexts. Existing alignment frameworks, structured approaches designed to align model behavior with human ethical and social norms, often rely on static datasets and post-hoc evaluations, offering limited insight into how ethical reasoning may evolve across different contexts or temporal scales. This study presents the Moral Consistency Pipeline (MoCoP), a dataset-free, closed-loop framework for continuously evalua&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03026v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:52:29 +0000</pubDate>
    </item>
    <item>
      <title>SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control</title>
      <link>http://arxiv.org/abs/2512.03028v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuxuan Mu, Ziyu Zhang, Yi Shi, Minami Matsumoto, Kotaro Imamura, Guy Tevet, Chuan Guo, Michael Taylor&lt;/p&gt;&lt;p&gt;Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03028v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:54:12 +0000</pubDate>
    </item>
    <item>
      <title>ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation</title>
      <link>http://arxiv.org/abs/2512.03036v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mengchen Zhang, Qi Chen, Tong Wu, Zihan Liu, Dahua Lin&lt;/p&gt;&lt;p&gt;Despite progress in video-to-audio generation, the field focuses predominantly on mono output, lacking spatial immersion. Existing binaural approaches remain constrained by a two-stage pipeline that first generates mono audio and then performs spatialization, often resulting in error accumulation and spatio-temporal inconsistencies. To address this limitation, we introduce the task of end-to-end binaural spatial audio generation directly from silent video&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 数据：包含再分析/卫星/观测等来源。&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03036v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:56:12 +0000</pubDate>
    </item>
    <item>
      <title>Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation</title>
      <link>http://arxiv.org/abs/2512.03040v1</link>
      <description>&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zeqi Xiao, Yiwei Zhao, Lingxiao Li, Yushi Lan, Yu Ning, Rahul Garg, Roshni Cooper, Mohammad H. Taghavi&lt;/p&gt;&lt;p&gt;We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform complex spatial tasks. We validate on two tasks: scene navigation - following camera-pose instructions while remaining consistent with 3D geometry of the scene, and object grounding - which requires semantic localization, instruction following, and planning&lt;br/&gt;&lt;br/&gt;要点：&lt;br/&gt;- 方法：采用机器学习/深度学习模型。&lt;/p&gt;</description>
      <guid isPermaLink="false">2512.03040v1</guid>
      <pubDate>Tue, 02 Dec 2025 18:59:44 +0000</pubDate>
    </item>
  </channel>
</rss>
